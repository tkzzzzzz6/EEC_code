# PVODæ•°æ®é›†åˆ†æå™¨ (ä¿®æ­£ç‰ˆ - ç®€åŒ–ä¸­æ–‡å­—ä½“è®¾ç½®)
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from pathlib import Path
from typing import Dict, List, Tuple
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from scipy import stats
import matplotlib.dates as mdates
import matplotlib

# ç®€åŒ–çš„ä¸­æ–‡å­—ä½“è®¾ç½®
import matplotlib as mpl
font_path = 'C:/Windows/Fonts/simhei.ttf'
mpl.font_manager.fontManager.addfont(font_path)  
mpl.rc('font', family='simhei')

# è®¾ç½®è­¦å‘Š
warnings.filterwarnings('ignore')

class PVODAnalyzerCorrectedFixed:
    """PVODå…‰ä¼æ•°æ®é›†åˆ†æå™¨ (ä¿®æ­£ç‰ˆ - ç®€åŒ–ä¸­æ–‡å­—ä½“è®¾ç½®)"""
    
    def __init__(self, data_dir: str = "PVODdatasets_v1.0", figures_dir: str = "Figures"):
        self.data_dir = Path(data_dir)
        self.figures_dir = Path(figures_dir)
        self.figures_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®åŸºæœ¬å›¾è¡¨æ ·å¼
        plt.style.use('default')
        sns.set_palette("husl")
        plt.rcParams['axes.unicode_minus'] = False
        
        # æ•°æ®åˆ—æ˜ å°„
        self.column_mapping = {
            'date_time': 'æ—¶é—´',
            'nwp_globalirrad': 'NWPå…¨çƒè¾å°„',
            'nwp_directirrad': 'NWPç›´å°„è¾å°„',
            'nwp_temperature': 'NWPæ¸©åº¦',
            'nwp_humidity': 'NWPæ¹¿åº¦',
            'nwp_windspeed': 'NWPé£é€Ÿ',
            'nwp_winddirection': 'NWPé£å‘',
            'nwp_pressure': 'NWPæ°”å‹',
            'lmd_totalirrad': 'LMDæ€»è¾å°„',
            'lmd_diffuseirrad': 'LMDæ•£å°„è¾å°„',
            'lmd_temperature': 'LMDæ¸©åº¦',
            'lmd_pressure': 'LMDæ°”å‹',
            'lmd_winddirection': 'LMDé£å‘',
            'lmd_windspeed': 'LMDé£é€Ÿ',
            'power': 'åŠŸç‡(MW)'
        }
    
    def test_chinese_display(self):
        """æµ‹è¯•ä¸­æ–‡æ˜¾ç¤ºæ•ˆæœ"""
        print("ğŸ§ª æµ‹è¯•ä¸­æ–‡å­—ä½“æ˜¾ç¤º...")
        
        fig, ax = plt.subplots(1, 1, figsize=(8, 6))
        
        # æµ‹è¯•æ•°æ®
        test_data = [20, 18, 16, 15, 14]
        test_labels = ['station00', 'station01', 'station02', 'station03', 'station04']
        
        bars = ax.bar(test_labels, test_data, color=['#e74c3c', '#f39c12', '#f1c40f', '#2ecc71', '#3498db'])
        ax.set_title('PVODå…‰ä¼ç«™ç‚¹å®¹é‡å› å­æµ‹è¯•å›¾', fontsize=14, fontweight='bold')
        ax.set_xlabel('å…‰ä¼ç«™ç‚¹ç¼–å·')
        ax.set_ylabel('å®¹é‡å› å­ (%)')
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, val in zip(bars, test_data):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, 
                   f'{val}%', ha='center', fontweight='bold')
        
        # æ·»åŠ è¯´æ˜æ–‡å­—
        ax.text(0.5, 0.95, 'å¦‚æœæ‚¨èƒ½çœ‹åˆ°è¿™äº›ä¸­æ–‡å­—ç¬¦ï¼Œè¯´æ˜å­—ä½“é…ç½®æˆåŠŸï¼', 
               transform=ax.transAxes, ha='center', va='top', 
               bbox=dict(boxstyle="round,pad=0.3", facecolor='lightblue', alpha=0.7))
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'chinese_font_test_simplified.png', 
                   dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        print("âœ“ ä¸­æ–‡å­—ä½“æµ‹è¯•å›¾å·²ä¿å­˜: Figures/chinese_font_test_simplified.png")
        
    def load_metadata(self) -> pd.DataFrame:
        """åŠ è½½å…ƒæ•°æ®"""
        metadata_path = self.data_dir / "metadata.csv"
        metadata = pd.read_csv(metadata_path)
        return metadata
    
    def load_station_data(self, station_id: str) -> pd.DataFrame:
        """åŠ è½½å•ä¸ªç«™ç‚¹æ•°æ®"""
        file_path = self.data_dir / f"{station_id}.csv"
        if not file_path.exists():
            print(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return pd.DataFrame()
        
        try:
            df = pd.read_csv(file_path)
            
            # æ•°æ®æ¸…ç†
            df = self._clean_data(df)
            
            # æ—¶é—´å¤„ç†
            df = self._process_time_data(df)
            
            return df
        except Exception as e:
            print(f"åŠ è½½ {station_id} æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†æ•°æ®"""
        # å¤„ç†æ—¶é—´åˆ—
        if 'date_time' in df.columns:
            df['date_time'] = pd.to_datetime(df['date_time'], errors='coerce')
        
        # è½¬æ¢æ•°å€¼åˆ—
        numeric_columns = [col for col in df.columns if col != 'date_time']
        for col in numeric_columns:
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        # ç§»é™¤å¼‚å¸¸å€¼
        for col in numeric_columns:
            if col == 'power':
                # åŠŸç‡ä¸èƒ½ä¸ºè´Ÿå€¼
                df[col] = df[col].clip(lower=0)
            elif 'irrad' in col:
                # è¾å°„å€¼ä¸èƒ½ä¸ºè´Ÿ
                df[col] = df[col].clip(lower=0)
            elif 'temperature' in col:
                # æ¸©åº¦èŒƒå›´é™åˆ¶
                df[col] = df[col].clip(-50, 60)
            elif 'humidity' in col:
                # æ¹¿åº¦èŒƒå›´é™åˆ¶
                df[col] = df[col].clip(0, 100)
            elif 'windspeed' in col:
                # é£é€Ÿä¸èƒ½ä¸ºè´Ÿ
                df[col] = df[col].clip(lower=0)
        
        return df
    
    def _process_time_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤„ç†æ—¶é—´æ•°æ®"""
        if 'date_time' in df.columns:
            df['hour'] = df['date_time'].dt.hour
            df['day'] = df['date_time'].dt.day
            df['month'] = df['date_time'].dt.month
            df['year'] = df['date_time'].dt.year
            df['season'] = df['month'].map({
                12: 'å†¬å­£', 1: 'å†¬å­£', 2: 'å†¬å­£',
                3: 'æ˜¥å­£', 4: 'æ˜¥å­£', 5: 'æ˜¥å­£',
                6: 'å¤å­£', 7: 'å¤å­£', 8: 'å¤å­£',
                9: 'ç§‹å­£', 10: 'ç§‹å­£', 11: 'ç§‹å­£'
            })
            df['weekday'] = df['date_time'].dt.day_name()
            
            # æ·»åŠ ç™½å¤©/å¤œæ™šæ ‡è®°
            df['is_daytime'] = (df['hour'] >= 6) & (df['hour'] <= 18)
            
        return df
    
    def load_all_stations(self) -> Tuple[Dict[str, pd.DataFrame], pd.DataFrame]:
        """åŠ è½½æ‰€æœ‰ç«™ç‚¹æ•°æ®"""
        metadata = self.load_metadata()
        station_data = {}
        
        for _, row in metadata.iterrows():
            station_id = row['Station_ID']
            print(f"æ­£åœ¨åŠ è½½ {station_id}...")
            
            df = self.load_station_data(station_id)
            if not df.empty:
                # æ·»åŠ å®¹é‡ä¿¡æ¯ - æ³¨æ„: metadataä¸­å®¹é‡å•ä½æ˜¯kWï¼ŒåŠŸç‡æ•°æ®å•ä½æ˜¯MW
                capacity_kw = row['Capacity']
                capacity_mw = capacity_kw / 1000  # è½¬æ¢ä¸ºMW
                
                df['capacity_kw'] = capacity_kw
                df['capacity_mw'] = capacity_mw
                # ä¿®æ­£å®¹é‡å› å­è®¡ç®—ï¼šåŠŸç‡æ•°æ®å·²ç»æ˜¯MWå•ä½
                df['capacity_factor'] = (df['power'] / capacity_mw) * 100
                df['technology'] = row['PV_Technology']
                df['longitude'] = row['Longitude']
                df['latitude'] = row['Latitude']
                
                station_data[station_id] = df
                print(f"{station_id} æ•°æ®åŠ è½½æˆåŠŸï¼Œå½¢çŠ¶: {df.shape}")
        
        return station_data, metadata
    
    def create_overview_analysis(self, station_data: Dict, metadata: pd.DataFrame):
        """åˆ›å»ºæ¦‚è§ˆåˆ†æ"""
        print("åˆ›å»ºæ•°æ®æ¦‚è§ˆåˆ†æ...")
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        fig.suptitle('PVODå…‰ä¼æ•°æ®é›†æ¦‚è§ˆåˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. å„ç«™ç‚¹è£…æœºå®¹é‡
        capacities = metadata['Capacity'].values / 1000  # è½¬æ¢ä¸ºMW
        station_names = metadata['Station_ID'].values
        
        bars = axes[0, 0].bar(range(len(station_names)), capacities, alpha=0.7, color='skyblue')
        axes[0, 0].set_title('å„ç«™ç‚¹è£…æœºå®¹é‡', fontweight='bold')
        axes[0, 0].set_xlabel('ç«™ç‚¹ç¼–å·')
        axes[0, 0].set_ylabel('è£…æœºå®¹é‡ (MW)')
        axes[0, 0].set_xticks(range(len(station_names)))
        axes[0, 0].set_xticklabels(station_names, rotation=45)
        axes[0, 0].grid(True, alpha=0.3)
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
        for bar, cap in zip(bars, capacities):
            height = bar.get_height()
            axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                           f'{cap:.0f}', ha='center', va='bottom', fontsize=9)
        
        # 2. åœ°ç†åˆ†å¸ƒ
        lons = metadata['Longitude'].values
        lats = metadata['Latitude'].values
        scatter = axes[0, 1].scatter(lons, lats, s=capacities*10, alpha=0.6, c=capacities, cmap='viridis')
        axes[0, 1].set_title('ç«™ç‚¹åœ°ç†åˆ†å¸ƒ', fontweight='bold')
        axes[0, 1].set_xlabel('ç»åº¦ (Â°)')
        axes[0, 1].set_ylabel('çº¬åº¦ (Â°)')
        axes[0, 1].grid(True, alpha=0.3)
        cbar = plt.colorbar(scatter, ax=axes[0, 1])
        cbar.set_label('è£…æœºå®¹é‡ (MW)')
        
        # æ·»åŠ ç«™ç‚¹æ ‡ç­¾
        for i, name in enumerate(station_names):
            axes[0, 1].annotate(name, (lons[i], lats[i]), xytext=(5, 5), 
                              textcoords='offset points', fontsize=8)
        
        # 3. æŠ€æœ¯ç±»å‹åˆ†å¸ƒ
        tech_counts = metadata['PV_Technology'].value_counts()
        colors = ['lightblue', 'lightcoral']
        wedges, texts, autotexts = axes[0, 2].pie(tech_counts.values, labels=tech_counts.index, 
                                                 autopct='%1.1f%%', colors=colors)
        axes[0, 2].set_title('å…‰ä¼æŠ€æœ¯ç±»å‹åˆ†å¸ƒ', fontweight='bold')
        
        # 4. æ•°æ®æ—¶é—´è·¨åº¦
        time_spans = []
        data_counts = []
        for station_id, df in station_data.items():
            if 'date_time' in df.columns:
                time_span = (df['date_time'].max() - df['date_time'].min()).days
                time_spans.append(time_span)
                data_counts.append(len(df))
        
        if time_spans:
            bars = axes[1, 0].bar(range(len(time_spans)), time_spans, alpha=0.7, color='orange')
            axes[1, 0].set_title('å„ç«™ç‚¹æ•°æ®æ—¶é—´è·¨åº¦', fontweight='bold')
            axes[1, 0].set_xlabel('ç«™ç‚¹ç¼–å·')
            axes[1, 0].set_ylabel('æ•°æ®è·¨åº¦ (å¤©)')
            axes[1, 0].set_xticks(range(len(station_names)))
            axes[1, 0].set_xticklabels(station_names, rotation=45)
            axes[1, 0].grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, span in zip(bars, time_spans):
                height = bar.get_height()
                axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + 5,
                               f'{span}å¤©', ha='center', va='bottom', fontsize=8)
        
        # 5. æ•°æ®é‡åˆ†å¸ƒ
        if data_counts:
            bars = axes[1, 1].bar(range(len(data_counts)), data_counts, alpha=0.7, color='green')
            axes[1, 1].set_title('å„ç«™ç‚¹æ•°æ®è®°å½•é‡', fontweight='bold')
            axes[1, 1].set_xlabel('ç«™ç‚¹ç¼–å·')
            axes[1, 1].set_ylabel('æ•°æ®è®°å½•æ•°')
            axes[1, 1].set_xticks(range(len(station_names)))
            axes[1, 1].set_xticklabels(station_names, rotation=45)
            axes[1, 1].grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, count in zip(bars, data_counts):
                height = bar.get_height()
                axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 500,
                               f'{count:,}', ha='center', va='bottom', fontsize=8, rotation=90)
        
        # 6. å„ç«™ç‚¹å¹³å‡å®¹é‡å› å­
        avg_cf = []
        for station_id, df in station_data.items():
            avg_cf.append(df['capacity_factor'].mean())
        
        if avg_cf:
            colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(avg_cf)))
            bars = axes[1, 2].bar(range(len(station_names)), avg_cf, alpha=0.8, color=colors)
            axes[1, 2].set_title('å„ç«™ç‚¹å¹³å‡å®¹é‡å› å­', fontweight='bold')
            axes[1, 2].set_xlabel('ç«™ç‚¹ç¼–å·')
            axes[1, 2].set_ylabel('å¹³å‡å®¹é‡å› å­ (%)')
            axes[1, 2].set_xticks(range(len(station_names)))
            axes[1, 2].set_xticklabels(station_names, rotation=45)
            axes[1, 2].grid(True, alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, cf in zip(bars, avg_cf):
                height = bar.get_height()
                axes[1, 2].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                               f'{cf:.1f}%', ha='center', va='bottom', fontsize=9)
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'pvod_overview_analysis_fixed.png', 
                   dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        print("âœ“ æ¦‚è§ˆåˆ†æå›¾è¡¨å·²ä¿å­˜")
    
    def create_power_generation_analysis(self, station_data: Dict):
        """åˆ›å»ºå‘ç”µåˆ†æ"""
        print("åˆ›å»ºå‘ç”µåˆ†æ...")
        
        fig, axes = plt.subplots(3, 2, figsize=(16, 18))
        fig.suptitle('PVODå…‰ä¼å‘ç”µæ·±åº¦åˆ†æ', fontsize=16, fontweight='bold')
        
        # æ”¶é›†æ‰€æœ‰ç«™ç‚¹æ•°æ®
        all_power = []
        all_cf = []
        all_hours = []
        all_months = []
        station_labels = []
        
        for station_id, df in station_data.items():
            power_data = df['power'].dropna()
            cf_data = df['capacity_factor'].dropna()
            
            all_power.extend(power_data)
            all_cf.extend(cf_data)
            station_labels.extend([station_id] * len(power_data))
            
            if 'hour' in df.columns:
                all_hours.extend(df['hour'])
            if 'month' in df.columns:
                all_months.extend(df['month'])
        
        # 1. åŠŸç‡åˆ†å¸ƒç›´æ–¹å›¾
        axes[0, 0].hist(all_power, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[0, 0].set_title('åŠŸç‡è¾“å‡ºåˆ†å¸ƒç›´æ–¹å›¾', fontweight='bold')
        axes[0, 0].set_xlabel('åŠŸç‡è¾“å‡º (MW)')
        axes[0, 0].set_ylabel('é¢‘æ¬¡')
        axes[0, 0].grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_power = np.mean(all_power)
        max_power = np.max(all_power)
        axes[0, 0].axvline(mean_power, color='red', linestyle='--', 
                          label=f'å¹³å‡å€¼: {mean_power:.1f} MW')
        axes[0, 0].axvline(max_power, color='green', linestyle='--', 
                          label=f'æœ€å¤§å€¼: {max_power:.1f} MW')
        axes[0, 0].legend()
        
        # 2. å®¹é‡å› å­åˆ†å¸ƒ
        axes[0, 1].hist(all_cf, bins=50, alpha=0.7, color='orange', edgecolor='black')
        axes[0, 1].set_title('å®¹é‡å› å­åˆ†å¸ƒç›´æ–¹å›¾', fontweight='bold')
        axes[0, 1].set_xlabel('å®¹é‡å› å­ (%)')
        axes[0, 1].set_ylabel('é¢‘æ¬¡')
        axes[0, 1].grid(True, alpha=0.3)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        mean_cf = np.mean(all_cf)
        axes[0, 1].axvline(mean_cf, color='red', linestyle='--', 
                          label=f'å¹³å‡å€¼: {mean_cf:.1f}%')
        axes[0, 1].legend()
        
        # 3. æ—¥å†…å‘ç”µæ¨¡å¼
        if all_hours:
            hour_power = pd.DataFrame({'hour': all_hours, 'power': all_power[:len(all_hours)]})
            hourly_avg = hour_power.groupby('hour')['power'].mean()
            axes[1, 0].plot(hourly_avg.index, hourly_avg.values, marker='o', linewidth=2, markersize=6)
            axes[1, 0].fill_between(hourly_avg.index, hourly_avg.values, alpha=0.3)
            axes[1, 0].set_title('24å°æ—¶æ—¥å†…å‘ç”µæ¨¡å¼', fontweight='bold')
            axes[1, 0].set_xlabel('å°æ—¶ (0-23)')
            axes[1, 0].set_ylabel('å¹³å‡åŠŸç‡ (MW)')
            axes[1, 0].grid(True, alpha=0.3)
            axes[1, 0].set_xlim(0, 23)
            
            # æ ‡æ³¨å³°å€¼æ—¶é—´
            peak_hour = hourly_avg.idxmax()
            peak_power = hourly_avg.max()
            axes[1, 0].annotate(f'å³°å€¼æ—¶é—´: {peak_hour}:00\nå³°å€¼åŠŸç‡: {peak_power:.1f} MW', 
                              xy=(peak_hour, peak_power), xytext=(peak_hour+2, peak_power+1),
                              arrowprops=dict(arrowstyle='->', color='red'),
                              bbox=dict(boxstyle="round,pad=0.3", facecolor='yellow', alpha=0.7))
        
        # 4. æœˆåº¦å‘ç”µæ¨¡å¼
        if all_months:
            month_power = pd.DataFrame({'month': all_months, 'power': all_power[:len(all_months)]})
            monthly_avg = month_power.groupby('month')['power'].mean()
            month_names = ['1æœˆ', '2æœˆ', '3æœˆ', '4æœˆ', '5æœˆ', '6æœˆ', 
                          '7æœˆ', '8æœˆ', '9æœˆ', '10æœˆ', '11æœˆ', '12æœˆ']
            
            bars = axes[1, 1].bar(monthly_avg.index, monthly_avg.values, alpha=0.7, color='green')
            axes[1, 1].set_title('æœˆåº¦å‘ç”µæ¨¡å¼åˆ†æ', fontweight='bold')
            axes[1, 1].set_xlabel('æœˆä»½')
            axes[1, 1].set_ylabel('å¹³å‡åŠŸç‡ (MW)')
            axes[1, 1].grid(True, alpha=0.3)
            axes[1, 1].set_xlim(0.5, 12.5)
            
            # è®¾ç½®xè½´æ ‡ç­¾
            axes[1, 1].set_xticks(range(1, 13))
            axes[1, 1].set_xticklabels([month_names[i-1] for i in monthly_avg.index], rotation=45)
            
            # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼
            for bar, month in zip(bars, monthly_avg.index):
                height = bar.get_height()
                axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.1,
                               f'{height:.1f}', ha='center', va='bottom', fontsize=8)
        
        # 5. å„ç«™ç‚¹åŠŸç‡ç®±çº¿å›¾
        power_by_station = [station_data[station]['power'].dropna() for station in station_data.keys()]
        station_names = list(station_data.keys())
        
        box_plot = axes[2, 0].boxplot(power_by_station, labels=station_names, patch_artist=True)
        colors = plt.cm.Set3(np.linspace(0, 1, len(box_plot['boxes'])))
        for patch, color in zip(box_plot['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        axes[2, 0].set_title('å„ç«™ç‚¹åŠŸç‡åˆ†å¸ƒç®±çº¿å›¾', fontweight='bold')
        axes[2, 0].set_xlabel('å…‰ä¼ç«™ç‚¹')
        axes[2, 0].set_ylabel('åŠŸç‡è¾“å‡º (MW)')
        axes[2, 0].tick_params(axis='x', rotation=45)
        axes[2, 0].grid(True, alpha=0.3)
        
        # 6. ç«™ç‚¹æ€§èƒ½æ’å
        station_stats = []
        labels = []
        for station_id, df in station_data.items():
            mean_cf = df['capacity_factor'].mean()
            station_stats.append(mean_cf)
            labels.append(station_id)
        
        # æŒ‰å®¹é‡å› å­æ’åº
        sorted_data = sorted(zip(labels, station_stats), key=lambda x: x[1], reverse=True)
        sorted_labels, sorted_stats = zip(*sorted_data)
        
        colors = plt.cm.RdYlGn(np.linspace(0.3, 0.9, len(sorted_stats)))
        bars = axes[2, 1].bar(range(len(sorted_labels)), sorted_stats, color=colors, alpha=0.8)
        axes[2, 1].set_title('å„ç«™ç‚¹å¹³å‡å®¹é‡å› å­æ€§èƒ½æ’å', fontweight='bold')
        axes[2, 1].set_xlabel('ç«™ç‚¹ (æŒ‰æ€§èƒ½æ’åº)')
        axes[2, 1].set_ylabel('å¹³å‡å®¹é‡å› å­ (%)')
        axes[2, 1].set_xticks(range(len(sorted_labels)))
        axes[2, 1].set_xticklabels(sorted_labels, rotation=45)
        axes[2, 1].grid(True, alpha=0.3)
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾å’Œæ’å
        for i, (bar, stat) in enumerate(zip(bars, sorted_stats)):
            height = bar.get_height()
            axes[2, 1].text(bar.get_x() + bar.get_width()/2., height + 0.5,
                           f'{stat:.1f}%', ha='center', va='bottom', fontsize=9)
            # æ·»åŠ æ’å
            axes[2, 1].text(bar.get_x() + bar.get_width()/2., height/2,
                           f'#{i+1}', ha='center', va='center', fontsize=10, fontweight='bold', color='white')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'pvod_power_analysis_fixed.png', 
                   dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        print("âœ“ å‘ç”µåˆ†æå›¾è¡¨å·²ä¿å­˜")
    
    def create_meteorological_correlation_analysis(self, station_data: Dict):
        """åˆ›å»ºæ°”è±¡ä¸å‘ç”µç›¸å…³æ€§åˆ†æ"""
        print("åˆ›å»ºæ°”è±¡ä¸å‘ç”µç›¸å…³æ€§åˆ†æ...")
        
        # é€‰æ‹©æ•°æ®é‡æœ€å¤§çš„ç«™ç‚¹
        max_data_station = max(station_data.items(), key=lambda x: len(x[1]))
        station_id, df = max_data_station
        
        fig, axes = plt.subplots(3, 3, figsize=(18, 15))
        fig.suptitle(f'æ°”è±¡æ¡ä»¶ä¸å‘ç”µç›¸å…³æ€§æ·±åº¦åˆ†æ (åŸºäº{station_id})', fontsize=16, fontweight='bold')
        
        # 1. NWPå…¨çƒè¾å°„vsåŠŸç‡
        valid_indices = df['nwp_globalirrad'].notna() & df['power'].notna()
        if valid_indices.sum() > 1000:
            sample_size = min(5000, valid_indices.sum())
            sample_df = df[valid_indices].sample(sample_size)
            
            axes[0, 0].scatter(sample_df['nwp_globalirrad'], sample_df['power'], alpha=0.3, s=2)
            axes[0, 0].set_title('NWPå…¨çƒè¾å°„ vs åŠŸç‡è¾“å‡º', fontweight='bold')
            axes[0, 0].set_xlabel('å…¨çƒè¾å°„å¼ºåº¦ (W/mÂ²)')
            axes[0, 0].set_ylabel('åŠŸç‡è¾“å‡º (MW)')
            axes[0, 0].grid(True, alpha=0.3)
            
            # è®¡ç®—ç›¸å…³ç³»æ•°
            corr = sample_df['nwp_globalirrad'].corr(sample_df['power'])
            axes[0, 0].text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr:.3f}', transform=axes[0, 0].transAxes, 
                           bbox=dict(boxstyle="round", facecolor='wheat', alpha=0.8))
        
        # 2. LMDæ€»è¾å°„vsåŠŸç‡
        valid_indices = df['lmd_totalirrad'].notna() & df['power'].notna()
        if valid_indices.sum() > 1000:
            sample_size = min(5000, valid_indices.sum())
            sample_df = df[valid_indices].sample(sample_size)
            
            axes[0, 1].scatter(sample_df['lmd_totalirrad'], sample_df['power'], alpha=0.3, s=2, color='orange')
            axes[0, 1].set_title('LMDæ€»è¾å°„ vs åŠŸç‡è¾“å‡º', fontweight='bold')
            axes[0, 1].set_xlabel('æ€»è¾å°„å¼ºåº¦ (W/mÂ²)')
            axes[0, 1].set_ylabel('åŠŸç‡è¾“å‡º (MW)')
            axes[0, 1].grid(True, alpha=0.3)
            
            corr = sample_df['lmd_totalirrad'].corr(sample_df['power'])
            axes[0, 1].text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr:.3f}', transform=axes[0, 1].transAxes, 
                           bbox=dict(boxstyle="round", facecolor='wheat', alpha=0.8))
        
        # 3. æ¸©åº¦vsåŠŸç‡
        valid_indices = df['nwp_temperature'].notna() & df['power'].notna()
        if valid_indices.sum() > 1000:
            sample_size = min(5000, valid_indices.sum())
            sample_df = df[valid_indices].sample(sample_size)
            
            axes[0, 2].scatter(sample_df['nwp_temperature'], sample_df['power'], alpha=0.3, s=2, color='red')
            axes[0, 2].set_title('NWPæ¸©åº¦ vs åŠŸç‡è¾“å‡º', fontweight='bold')
            axes[0, 2].set_xlabel('ç¯å¢ƒæ¸©åº¦ (Â°C)')
            axes[0, 2].set_ylabel('åŠŸç‡è¾“å‡º (MW)')
            axes[0, 2].grid(True, alpha=0.3)
            
            corr = sample_df['nwp_temperature'].corr(sample_df['power'])
            axes[0, 2].text(0.05, 0.95, f'ç›¸å…³ç³»æ•°: {corr:.3f}', transform=axes[0, 2].transAxes, 
                           bbox=dict(boxstyle="round", facecolor='wheat', alpha=0.8))
        
        # 4-6. æ°”è±¡å‚æ•°åˆ†å¸ƒ
        axes[1, 0].hist(df['nwp_globalirrad'].dropna(), bins=40, alpha=0.7, color='yellow', edgecolor='black')
        axes[1, 0].set_title('NWPå…¨çƒè¾å°„å¼ºåº¦åˆ†å¸ƒ', fontweight='bold')
        axes[1, 0].set_xlabel('è¾å°„å¼ºåº¦ (W/mÂ²)')
        axes[1, 0].set_ylabel('é¢‘æ¬¡')
        axes[1, 0].grid(True, alpha=0.3)
        
        axes[1, 1].hist(df['nwp_temperature'].dropna(), bins=40, alpha=0.7, color='red', edgecolor='black')
        axes[1, 1].set_title('NWPç¯å¢ƒæ¸©åº¦åˆ†å¸ƒ', fontweight='bold')
        axes[1, 1].set_xlabel('ç¯å¢ƒæ¸©åº¦ (Â°C)')
        axes[1, 1].set_ylabel('é¢‘æ¬¡')
        axes[1, 1].grid(True, alpha=0.3)
        
        axes[1, 2].hist(df['nwp_humidity'].dropna(), bins=40, alpha=0.7, color='blue', edgecolor='black')
        axes[1, 2].set_title('NWPç›¸å¯¹æ¹¿åº¦åˆ†å¸ƒ', fontweight='bold')
        axes[1, 2].set_xlabel('ç›¸å¯¹æ¹¿åº¦ (%)')
        axes[1, 2].set_ylabel('é¢‘æ¬¡')
        axes[1, 2].grid(True, alpha=0.3)
        
        # 7. å°æ—¶åŠŸç‡vsè¾å°„çƒ­å›¾
        if 'hour' in df.columns:
            # åˆ›å»ºå°æ—¶-è¾å°„çš„åŠŸç‡çƒ­å›¾
            df_clean = df[df['nwp_globalirrad'].notna() & df['power'].notna() & df['hour'].notna()]
            if len(df_clean) > 100:
                # å°†è¾å°„å€¼åˆ†ç»„
                df_clean['irrad_bins'] = pd.cut(df_clean['nwp_globalirrad'], bins=10)
                heatmap_data = df_clean.groupby(['hour', 'irrad_bins'])['power'].mean().reset_index()
                pivot_data = heatmap_data.pivot(index='irrad_bins', columns='hour', values='power')
                
                im = axes[2, 0].imshow(pivot_data.values, aspect='auto', cmap='YlOrRd')
                axes[2, 0].set_title('å°æ—¶-è¾å°„åŠŸç‡çƒ­åŠ›å›¾', fontweight='bold')
                axes[2, 0].set_xlabel('å°æ—¶ (0-23)')
                axes[2, 0].set_ylabel('è¾å°„å¼ºåº¦åŒºé—´')
                
                # è®¾ç½®åæ ‡è½´
                axes[2, 0].set_xticks(range(len(pivot_data.columns)))
                axes[2, 0].set_xticklabels(pivot_data.columns)
                axes[2, 0].set_yticks(range(len(pivot_data.index)))
                axes[2, 0].set_yticklabels([f'{i:.0f}-{j:.0f}' for i,j in 
                                          [(interval.left, interval.right) for interval in pivot_data.index]])
                
                plt.colorbar(im, ax=axes[2, 0], label='å¹³å‡åŠŸç‡ (MW)')
        
        # 8. å­£èŠ‚æ€§å‘ç”µvsè¾å°„
        if 'season' in df.columns:
            season_data = df.groupby('season').agg({
                'power': 'mean',
                'nwp_globalirrad': 'mean',
                'nwp_temperature': 'mean'
            }).reset_index()
            
            if len(season_data) > 1:
                seasons = season_data['season']
                x_pos = np.arange(len(seasons))
                
                ax1 = axes[2, 1]
                ax2 = ax1.twinx()
                
                bars1 = ax1.bar(x_pos - 0.2, season_data['power'], 0.4, label='å¹³å‡åŠŸç‡', alpha=0.7, color='green')
                bars2 = ax2.bar(x_pos + 0.2, season_data['nwp_globalirrad'], 0.4, label='å¹³å‡è¾å°„', alpha=0.7, color='orange')
                
                ax1.set_title('å­£èŠ‚æ€§å‘ç”µvsè¾å°„å¯¹æ¯”', fontweight='bold')
                ax1.set_xlabel('å­£èŠ‚')
                ax1.set_ylabel('å¹³å‡åŠŸç‡ (MW)', color='green')
                ax2.set_ylabel('å¹³å‡è¾å°„ (W/mÂ²)', color='orange')
                ax1.set_xticks(x_pos)
                ax1.set_xticklabels(seasons)
                
                # æ·»åŠ å›¾ä¾‹
                lines1, labels1 = ax1.get_legend_handles_labels()
                lines2, labels2 = ax2.get_legend_handles_labels()
                ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
        
        # 9. ç›¸å…³æ€§çŸ©é˜µçƒ­å›¾
        corr_cols = ['nwp_globalirrad', 'nwp_directirrad', 'nwp_temperature', 
                     'nwp_humidity', 'lmd_totalirrad', 'power']
        available_cols = [col for col in corr_cols if col in df.columns]
        
        if len(available_cols) >= 3:
            corr_matrix = df[available_cols].corr()
            
            im = axes[2, 2].imshow(corr_matrix.values, cmap='coolwarm', vmin=-1, vmax=1)
            axes[2, 2].set_title('æ°”è±¡-å‘ç”µç›¸å…³æ€§çŸ©é˜µ', fontweight='bold')
            
            # è®¾ç½®æ ‡ç­¾
            col_labels = [col.replace('nwp_', 'NWP_').replace('lmd_', 'LMD_').replace('_', '\n') for col in available_cols]
            axes[2, 2].set_xticks(range(len(available_cols)))
            axes[2, 2].set_yticks(range(len(available_cols)))
            axes[2, 2].set_xticklabels(col_labels, rotation=45)
            axes[2, 2].set_yticklabels(col_labels)
            
            # æ·»åŠ æ•°å€¼æ ‡æ³¨
            for i in range(len(available_cols)):
                for j in range(len(available_cols)):
                    text_color = 'white' if abs(corr_matrix.iloc[i, j]) > 0.5 else 'black'
                    axes[2, 2].text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', 
                                   ha='center', va='center', color=text_color, fontweight='bold')
            
            plt.colorbar(im, ax=axes[2, 2], label='ç›¸å…³ç³»æ•°')
        
        plt.tight_layout()
        plt.savefig(self.figures_dir / 'pvod_meteorological_correlation_analysis_fixed.png', 
                   dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        print("âœ“ æ°”è±¡ç›¸å…³æ€§åˆ†æå›¾è¡¨å·²ä¿å­˜")
    
    def generate_summary_report(self, station_data: Dict, metadata: pd.DataFrame):
        """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("PVODæ•°æ®é›†åˆ†ææ±‡æ€»æŠ¥å‘Š (ä¿®æ­£ç‰ˆ)")
        print("="*60)
        
        # åŸºæœ¬ä¿¡æ¯
        total_stations = len(station_data)
        total_capacity_kw = metadata['Capacity'].sum()
        total_capacity_mw = total_capacity_kw / 1000
        
        print(f"\nğŸ“Š åŸºæœ¬ä¿¡æ¯:")
        print(f"  æ€»ç«™ç‚¹æ•°: {total_stations}")
        print(f"  æ€»è£…æœºå®¹é‡: {total_capacity_kw:,} kW ({total_capacity_mw:.1f} MW)")
        
        # æŠ€æœ¯ç±»å‹åˆ†å¸ƒ
        tech_dist = metadata['PV_Technology'].value_counts()
        print(f"\nğŸ”§ æŠ€æœ¯ç±»å‹åˆ†å¸ƒ:")
        for tech, count in tech_dist.items():
            capacity_by_tech = metadata[metadata['PV_Technology'] == tech]['Capacity'].sum() / 1000
            print(f"  {tech}: {count} ä¸ªç«™ç‚¹, æ€»å®¹é‡ {capacity_by_tech:.1f} MW")
        
        # åœ°ç†åˆ†å¸ƒ
        lon_range = metadata['Longitude'].max() - metadata['Longitude'].min()
        lat_range = metadata['Latitude'].max() - metadata['Latitude'].min()
        print(f"\nğŸŒ åœ°ç†åˆ†å¸ƒ:")
        print(f"  ç»åº¦èŒƒå›´: {metadata['Longitude'].min():.2f}Â° - {metadata['Longitude'].max():.2f}Â° (è·¨åº¦{lon_range:.2f}Â°)")
        print(f"  çº¬åº¦èŒƒå›´: {metadata['Latitude'].min():.2f}Â° - {metadata['Latitude'].max():.2f}Â° (è·¨åº¦{lat_range:.2f}Â°)")
        print(f"  åœ°ç†ä¸­å¿ƒ: ({metadata['Longitude'].mean():.2f}Â°, {metadata['Latitude'].mean():.2f}Â°)")
        
        # æ€§èƒ½ç»Ÿè®¡
        all_cf = []
        all_power = []
        data_summary = []
        
        for station_id, df in station_data.items():
            capacity_mw = df['capacity_mw'].iloc[0]
            avg_power = df['power'].mean()
            max_power = df['power'].max()
            avg_cf = df['capacity_factor'].mean()
            max_cf = df['capacity_factor'].max()
            data_count = len(df)
            
            all_cf.append(avg_cf)
            all_power.append(avg_power)
            
            # æ—¶é—´èŒƒå›´
            if 'date_time' in df.columns:
                time_span = (df['date_time'].max() - df['date_time'].min()).days
                start_date = df['date_time'].min().strftime('%Y-%m-%d')
                end_date = df['date_time'].max().strftime('%Y-%m-%d')
            else:
                time_span = 0
                start_date = end_date = "æœªçŸ¥"
            
            # å‘ç”µæ—¶é—´ç»Ÿè®¡ï¼ˆåŠŸç‡>0çš„æ—¶é—´ï¼‰
            operating_hours = (df['power'] > 0).sum()
            operating_ratio = (operating_hours / len(df)) * 100
            
            data_summary.append({
                'station': station_id,
                'capacity_mw': capacity_mw,
                'avg_power': avg_power,
                'max_power': max_power,
                'avg_cf': avg_cf,
                'max_cf': max_cf,
                'data_count': data_count,
                'time_span': time_span,
                'start_date': start_date,
                'end_date': end_date,
                'operating_hours': operating_hours,
                'operating_ratio': operating_ratio
            })
        
        print(f"\nâš¡ æ•´ä½“æ€§èƒ½:")
        print(f"  å¹³å‡å®¹é‡å› å­: {np.mean(all_cf):.2f}%")
        print(f"  å®¹é‡å› å­èŒƒå›´: {np.min(all_cf):.2f}% - {np.max(all_cf):.2f}%")
        print(f"  æ€»å¹³å‡åŠŸç‡: {np.sum(all_power):.1f} MW")
        print(f"  æ•´ä½“å®¹é‡å› å­: {(np.sum(all_power)/total_capacity_mw)*100:.2f}%")
        print(f"  åŠŸç‡æ ‡å‡†å·®: {np.std(all_power):.2f} MW")
        
        # å„ç«™ç‚¹è¯¦ç»†ä¿¡æ¯
        print(f"\nğŸ“‹ å„ç«™ç‚¹è¯¦ç»†ä¿¡æ¯:")
        print("-" * 140)
        print(f"{'ç«™ç‚¹':<12} {'å®¹é‡(MW)':<10} {'å¹³å‡åŠŸç‡':<10} {'æœ€å¤§åŠŸç‡':<10} {'å®¹é‡å› å­':<10} {'æœ€å¤§CF':<10} {'è¿è¡Œæ—¶é—´':<10} {'æ•°æ®é‡':<8} {'æ—¶é—´è·¨åº¦':<8}")
        print("-" * 140)
        
        # æŒ‰å®¹é‡å› å­æ’åº
        data_summary.sort(key=lambda x: x['avg_cf'], reverse=True)
        
        for info in data_summary:
            print(f"{info['station']:<12} {info['capacity_mw']:<10.1f} "
                  f"{info['avg_power']:<10.2f} {info['max_power']:<10.2f} "
                  f"{info['avg_cf']:<10.1f}% {info['max_cf']:<10.1f}% "
                  f"{info['operating_ratio']:<10.1f}% {info['data_count']:<8} {info['time_span']:<8}å¤©")
        
        print("-" * 140)
        
        # æ€§èƒ½æ’å
        best_station = max(data_summary, key=lambda x: x['avg_cf'])
        worst_station = min(data_summary, key=lambda x: x['avg_cf'])
        highest_max = max(data_summary, key=lambda x: x['max_power'])
        
        print(f"\nğŸ† æ€§èƒ½æ’å:")
        print(f"  æœ€ä½³å¹³å‡æ€§èƒ½: {best_station['station']} (å®¹é‡å› å­: {best_station['avg_cf']:.1f}%)")
        print(f"  æœ€å·®å¹³å‡æ€§èƒ½: {worst_station['station']} (å®¹é‡å› å­: {worst_station['avg_cf']:.1f}%)")
        print(f"  æœ€é«˜åŠŸç‡è¾“å‡º: {highest_max['station']} (æœ€å¤§åŠŸç‡: {highest_max['max_power']:.1f} MW)")
        
        # æ—¶é—´åˆ†æ
        print(f"\nğŸ“… æ—¶é—´åˆ†æ:")
        all_start_dates = [info['start_date'] for info in data_summary if info['start_date'] != 'æœªçŸ¥']
        all_end_dates = [info['end_date'] for info in data_summary if info['end_date'] != 'æœªçŸ¥']
        
        if all_start_dates and all_end_dates:
            earliest_start = min(all_start_dates)
            latest_end = max(all_end_dates)
            print(f"  æ•°æ®æ—¶é—´èŒƒå›´: {earliest_start} ~ {latest_end}")
            
            avg_operating_ratio = np.mean([info['operating_ratio'] for info in data_summary])
            print(f"  å¹³å‡è¿è¡Œæ—¶é—´æ¯”ä¾‹: {avg_operating_ratio:.1f}%")
        
        # æ•°æ®è´¨é‡è¯„ä¼°
        print(f"\nğŸ“ˆ æ•°æ®è´¨é‡:")
        total_records = sum(info['data_count'] for info in data_summary)
        avg_records = total_records / len(data_summary)
        print(f"  æ€»æ•°æ®è®°å½•: {total_records:,}")
        print(f"  å¹³å‡æ¯ç«™ç‚¹: {avg_records:.0f} æ¡è®°å½•")
        print(f"  æ•°æ®æ—¶é—´åˆ†è¾¨ç‡: 15åˆ†é’Ÿé—´éš”")
        
        # è®¡ç®—å„ç«™ç‚¹åŠŸç‡æ•°æ®ç¼ºå¤±ç‡
        missing_rates = []
        for station_id, df in station_data.items():
            missing_rate = (df['power'].isna().sum() / len(df)) * 100
            missing_rates.append(missing_rate)
            if missing_rate > 5:
                print(f"  âš ï¸  {station_id} åŠŸç‡æ•°æ®ç¼ºå¤±ç‡: {missing_rate:.1f}%")
        
        avg_missing_rate = np.mean(missing_rates)
        print(f"  å¹³å‡åŠŸç‡æ•°æ®ç¼ºå¤±ç‡: {avg_missing_rate:.3f}%")
        
        # æŠ€æœ¯ç±»å‹æ€§èƒ½æ¯”è¾ƒ
        print(f"\nğŸ”¬ æŠ€æœ¯ç±»å‹æ€§èƒ½:")
        tech_performance = {}
        for station_id, df in station_data.items():
            tech = df['technology'].iloc[0]
            avg_cf = df['capacity_factor'].mean()
            if tech not in tech_performance:
                tech_performance[tech] = []
            tech_performance[tech].append(avg_cf)
        
        for tech, cf_list in tech_performance.items():
            avg_cf = np.mean(cf_list)
            std_cf = np.std(cf_list)
            print(f"  {tech}: å¹³å‡å®¹é‡å› å­ {avg_cf:.2f}% (Â±{std_cf:.2f}%)")
        
        print("\n" + "="*60)
        print("âœ… åˆ†æå®Œæˆï¼æ‰€æœ‰å›¾è¡¨å·²ä¿å­˜åˆ° Figures ç›®å½•")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("  ğŸ“Š pvod_overview_analysis_fixed.png - æ•°æ®æ¦‚è§ˆåˆ†æ")
        print("  âš¡ pvod_power_analysis_fixed.png - å‘ç”µåˆ†æ")
        print("  ğŸŒ¡ï¸ pvod_meteorological_correlation_analysis_fixed.png - æ°”è±¡ç›¸å…³æ€§åˆ†æ")
        print("  ğŸ§ª chinese_font_test_simplified.png - ä¸­æ–‡å­—ä½“æµ‹è¯•")
        print("="*60)
    
    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¼€å§‹PVODæ•°æ®é›†å…¨é¢åˆ†æ (ä¿®æ­£ç‰ˆ - ç®€åŒ–ä¸­æ–‡å­—ä½“è®¾ç½®)...")
        
        # æµ‹è¯•ä¸­æ–‡å­—ä½“
        self.test_chinese_display()
        
        # åŠ è½½æ‰€æœ‰æ•°æ®
        station_data, metadata = self.load_all_stations()
        
        if not station_data:
            print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆæ•°æ®ï¼Œåˆ†æç»ˆæ­¢")
            return
        
        print(f"\nâœ… æˆåŠŸåŠ è½½ {len(station_data)} ä¸ªç«™ç‚¹çš„æ•°æ®")
        
        # æ‰§è¡Œå„ç§åˆ†æ
        self.create_overview_analysis(station_data, metadata)
        self.create_power_generation_analysis(station_data)
        self.create_meteorological_correlation_analysis(station_data)
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        self.generate_summary_report(station_data, metadata)


def main():
    """ä¸»å‡½æ•°"""
    try:
        analyzer = PVODAnalyzerCorrectedFixed()
        analyzer.run_full_analysis()
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 