# NWPä¿¡æ¯èå…¥çš„å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹è¯„ä»·æŒ‡æ ‡è®¡ç®— + å¯è§†åŒ–
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

# ç®€åŒ–çš„ä¸­æ–‡å­—ä½“è®¾ç½®
import matplotlib as mpl
font_path = 'C:/Windows/Fonts/simhei.ttf'
mpl.font_manager.fontManager.addfont(font_path)  
mpl.rc('font', family='simhei')
plt.rcParams['axes.unicode_minus'] = False

sns.set_palette("husl")
plt.ioff()

class NWPPowerPredictionEvaluator:
    """NWPä¿¡æ¯èå…¥çš„å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹è¯„ä»·æŒ‡æ ‡è®¡ç®—å™¨"""
    
    def __init__(self, capacity):
        """
        åˆå§‹åŒ–è¯„ä»·å™¨
        
        Args:
            capacity: å¼€æœºå®¹é‡ (MW)
        """
        self.capacity = capacity
    
    def ensure_chinese_font(self):
        """ç¡®ä¿ä¸­æ–‡å­—ä½“è®¾ç½®æ­£ç¡®åº”ç”¨"""
        mpl.rc('font', family='simhei')
        plt.rcParams['axes.unicode_minus'] = False
    
    def calculate_metrics(self, actual_power, predicted_power, only_daytime=True):
        """
        è®¡ç®—è¯„ä»·æŒ‡æ ‡
        
        Args:
            actual_power: å®é™…åŠŸç‡æ•°ç»„
            predicted_power: é¢„æµ‹åŠŸç‡æ•°ç»„
            only_daytime: æ˜¯å¦åªè®¡ç®—ç™½å¤©æ—¶æ®µæŒ‡æ ‡
            
        Returns:
            dict: åŒ…å«æ‰€æœ‰è¯„ä»·æŒ‡æ ‡çš„å­—å…¸
        """
        # ç¡®ä¿æ•°ç»„é•¿åº¦ä¸€è‡´
        min_len = min(len(actual_power), len(predicted_power))
        actual = np.array(actual_power[:min_len])
        predicted = np.array(predicted_power[:min_len])
        
        if only_daytime:
            # åªè®¡ç®—ç™½å¤©æ—¶æ®µï¼ˆåŠŸç‡å¤§äº0çš„æ—¶æ®µï¼‰
            daytime_mask = (actual > 0) | (predicted > 0)
            if np.sum(daytime_mask) == 0:
                return {}
            actual = actual[daytime_mask]
            predicted = predicted[daytime_mask]
        
        n = len(actual)
        
        # å½’ä¸€åŒ–è¯¯å·®ï¼ˆç›¸å¯¹äºå¼€æœºå®¹é‡ï¼‰
        normalized_actual = actual / self.capacity
        normalized_predicted = predicted / self.capacity
        normalized_error = normalized_predicted - normalized_actual
        
        # 1. å‡æ–¹æ ¹è¯¯å·® (RMSE)
        rmse = np.sqrt(np.mean(normalized_error ** 2))
        
        # 2. å¹³å‡ç»å¯¹è¯¯å·® (MAE)
        mae = np.mean(np.abs(normalized_error))
        
        # 3. å¹³å‡è¯¯å·® (ME)
        me = np.mean(normalized_error)
        
        # 4. ç›¸å…³ç³»æ•° (r)
        if n > 1 and np.std(actual) > 0 and np.std(predicted) > 0:
            correlation = np.corrcoef(actual, predicted)[0, 1]
        else:
            correlation = 0
        
        # 5. å‡†ç¡®ç‡ (CR)
        accuracy = (1 - rmse) * 100
        
        # 6. åˆæ ¼ç‡ (QR) - è¯¯å·®å°äº25%çš„æ¯”ä¾‹
        qualified_mask = np.abs(normalized_error) < 0.25
        qualification_rate = np.sum(qualified_mask) / n * 100
        
        # 7. é¢å¤–çš„NWPè¯„ä»·æŒ‡æ ‡
        # å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·® (MAPE)
        mape = np.mean(np.abs(normalized_error)) * 100
        
        # æ ‡å‡†åŒ–å‡æ–¹æ ¹è¯¯å·® (NRMSE)
        nrmse = rmse / (np.max(normalized_actual) - np.min(normalized_actual)) if np.max(normalized_actual) != np.min(normalized_actual) else 0
        
        return {
            'RMSE': rmse,
            'MAE': mae,
            'ME': me,
            'Correlation': correlation,
            'Accuracy': accuracy,
            'Qualification_Rate': qualification_rate,
            'MAPE': mape,
            'NRMSE': nrmse,
            'Sample_Count': n
        }
    
    def compare_models(self, actual_power, model_predictions, model_names):
        """
        å¯¹æ¯”å¤šä¸ªæ¨¡å‹çš„æ€§èƒ½
        
        Args:
            actual_power: å®é™…åŠŸç‡æ•°ç»„
            model_predictions: å­—å…¸ï¼ŒåŒ…å«å„æ¨¡å‹çš„é¢„æµ‹ç»“æœ
            model_names: æ¨¡å‹åç§°åˆ—è¡¨
            
        Returns:
            dict: å„æ¨¡å‹çš„è¯„ä»·æŒ‡æ ‡
        """
        all_metrics = {}
        
        for model_name in model_names:
            if model_name in model_predictions:
                metrics = self.calculate_metrics(actual_power, model_predictions[model_name])
                all_metrics[model_name] = metrics
        
        return all_metrics
    
    def analyze_nwp_effectiveness(self, all_metrics):
        """
        åˆ†æNWPä¿¡æ¯çš„æœ‰æ•ˆæ€§
        
        Args:
            all_metrics: åŒ…å«å„æ¨¡å‹è¯„ä»·æŒ‡æ ‡çš„å­—å…¸
            
        Returns:
            dict: NWPæœ‰æ•ˆæ€§åˆ†æç»“æœ
        """
        if 'basic' not in all_metrics or 'nwp_enhanced' not in all_metrics:
            return {}
        
        basic_metrics = all_metrics['basic']
        nwp_metrics = all_metrics['nwp_enhanced']
        
        # è®¡ç®—æ”¹å–„ç¨‹åº¦
        rmse_improvement = (basic_metrics['RMSE'] - nwp_metrics['RMSE']) / basic_metrics['RMSE'] * 100
        mae_improvement = (basic_metrics['MAE'] - nwp_metrics['MAE']) / basic_metrics['MAE'] * 100
        accuracy_improvement = nwp_metrics['Accuracy'] - basic_metrics['Accuracy']
        correlation_improvement = nwp_metrics['Correlation'] - basic_metrics['Correlation']
        qualification_improvement = nwp_metrics['Qualification_Rate'] - basic_metrics['Qualification_Rate']
        
        # åˆ¤æ–­æœ‰æ•ˆæ€§ç­‰çº§
        if rmse_improvement > 5 and accuracy_improvement > 2:
            effectiveness_level = "æ˜¾è‘—æœ‰æ•ˆ"
        elif rmse_improvement > 2 and accuracy_improvement > 1:
            effectiveness_level = "æœ‰æ•ˆ"
        elif rmse_improvement > 0:
            effectiveness_level = "è½»å¾®æœ‰æ•ˆ"
        else:
            effectiveness_level = "æ— æ•ˆæˆ–è´Ÿé¢å½±å“"
        
        return {
            'rmse_improvement': rmse_improvement,
            'mae_improvement': mae_improvement,
            'accuracy_improvement': accuracy_improvement,
            'correlation_improvement': correlation_improvement,
            'qualification_improvement': qualification_improvement,
            'effectiveness_level': effectiveness_level
        }
    
    def create_nwp_comparison_visualization(self, actual, model_predictions, station_id, save_dir="results/figures"):
        """åˆ›å»ºNWPå¯¹æ¯”å¯è§†åŒ–å›¾è¡¨"""
        self.ensure_chinese_font()
        
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        # åªä½¿ç”¨ç™½å¤©æ—¶æ®µçš„æ•°æ®
        daytime_mask = actual > 0
        actual_day = actual[daytime_mask]
        
        if len(actual_day) == 0:
            print(f"âš ï¸ {station_id} æ²¡æœ‰ç™½å¤©æ—¶æ®µæ•°æ®ï¼Œè·³è¿‡å¯è§†åŒ–")
            return
        
        # åˆ›å»ºç»¼åˆå¯¹æ¯”å›¾è¡¨
        fig, axes = plt.subplots(3, 2, figsize=(16, 18))
        fig.suptitle(f'{station_id} NWPä¿¡æ¯èå…¥æ•ˆæœåˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. æ—¶é—´åºåˆ—å¯¹æ¯”
        ax1 = axes[0, 0]
        time_index = range(len(actual))
        ax1.plot(time_index, actual, label='å®é™…åŠŸç‡', alpha=0.8, linewidth=1.5, color='black')
        
        colors = ['red', 'blue', 'green', 'orange', 'purple']
        for i, (model_name, predictions) in enumerate(model_predictions.items()):
            if i < len(colors):
                ax1.plot(time_index, predictions, label=f'{model_name}', 
                        alpha=0.7, linewidth=1.2, color=colors[i])
        
        ax1.set_title('æ—¶é—´åºåˆ—å¯¹æ¯”')
        ax1.set_xlabel('æ—¶é—´ç‚¹')
        ax1.set_ylabel('åŠŸç‡ (MW)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. æ•£ç‚¹å›¾å¯¹æ¯”ï¼ˆåŸºç¡€æ¨¡å‹ vs NWPå¢å¼ºæ¨¡å‹ï¼‰
        ax2 = axes[0, 1]
        if 'basic' in model_predictions and 'nwp_enhanced' in model_predictions:
            basic_day = model_predictions['basic'][daytime_mask]
            nwp_day = model_predictions['nwp_enhanced'][daytime_mask]
            
            ax2.scatter(actual_day, basic_day, alpha=0.6, s=20, color='red', label='åŸºç¡€æ¨¡å‹')
            ax2.scatter(actual_day, nwp_day, alpha=0.6, s=20, color='blue', label='NWPå¢å¼ºæ¨¡å‹')
            
            max_val = max(actual_day.max(), basic_day.max(), nwp_day.max())
            ax2.plot([0, max_val], [0, max_val], 'k--', label='ç†æƒ³é¢„æµ‹çº¿')
            ax2.set_title('æ•£ç‚¹å›¾å¯¹æ¯” (ä»…ç™½å¤©æ—¶æ®µ)')
            ax2.set_xlabel('å®é™…åŠŸç‡ (MW)')
            ax2.set_ylabel('é¢„æµ‹åŠŸç‡ (MW)')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
        
        # 3. è¯¯å·®åˆ†å¸ƒå¯¹æ¯”
        ax3 = axes[1, 0]
        if 'basic' in model_predictions and 'nwp_enhanced' in model_predictions:
            basic_errors = model_predictions['basic'][daytime_mask] - actual_day
            nwp_errors = model_predictions['nwp_enhanced'][daytime_mask] - actual_day
            
            ax3.hist(basic_errors, bins=30, alpha=0.7, color='red', label='åŸºç¡€æ¨¡å‹è¯¯å·®', density=True)
            ax3.hist(nwp_errors, bins=30, alpha=0.7, color='blue', label='NWPå¢å¼ºæ¨¡å‹è¯¯å·®', density=True)
            ax3.axvline(basic_errors.mean(), color='red', linestyle='--', alpha=0.8)
            ax3.axvline(nwp_errors.mean(), color='blue', linestyle='--', alpha=0.8)
            ax3.set_title('è¯¯å·®åˆ†å¸ƒå¯¹æ¯”')
            ax3.set_xlabel('é¢„æµ‹è¯¯å·® (MW)')
            ax3.set_ylabel('å¯†åº¦')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
        
        # 4. æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾
        ax4 = axes[1, 1]
        all_metrics = self.compare_models(actual, model_predictions, list(model_predictions.keys()))
        
        if len(all_metrics) >= 2:
            # é€‰æ‹©ä¸»è¦çš„ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œé›·è¾¾å›¾å¯¹æ¯”
            models_to_compare = ['basic', 'nwp_enhanced'] if 'basic' in all_metrics and 'nwp_enhanced' in all_metrics else list(all_metrics.keys())[:2]
            
            categories = ['å‡†ç¡®ç‡', 'åˆæ ¼ç‡', 'ç›¸å…³ç³»æ•°', 'RMSE(å)', 'MAE(å)']
            angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)
            angles = np.concatenate((angles, [angles[0]]))
            
            ax4 = plt.subplot(3, 2, 4, projection='polar')
            
            for model_name in models_to_compare:
                if model_name in all_metrics:
                    metrics = all_metrics[model_name]
                    values = [
                        metrics['Accuracy'],
                        metrics['Qualification_Rate'],
                        metrics['Correlation'] * 100,
                        (1 - metrics['RMSE']) * 100,
                        (1 - metrics['MAE']) * 100
                    ]
                    values += values[:1]
                    
                    ax4.plot(angles, values, 'o-', linewidth=2, label=model_name)
                    ax4.fill(angles, values, alpha=0.25)
            
            ax4.set_xticks(angles[:-1])
            ax4.set_xticklabels(categories)
            ax4.set_ylim(0, 100)
            ax4.set_title('æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾', pad=20)
            ax4.legend()
            ax4.grid(True)
        
        # 5. æ”¹å–„æ•ˆæœåˆ†æ
        ax5 = axes[2, 0]
        if len(all_metrics) >= 2:
            effectiveness_analysis = self.analyze_nwp_effectiveness(all_metrics)
            
            if effectiveness_analysis:
                improvements = [
                    effectiveness_analysis['rmse_improvement'],
                    effectiveness_analysis['mae_improvement'],
                    effectiveness_analysis['accuracy_improvement'],
                    effectiveness_analysis['correlation_improvement'] * 100,
                    effectiveness_analysis['qualification_improvement']
                ]
                
                improvement_names = ['RMSEæ”¹å–„(%)', 'MAEæ”¹å–„(%)', 'å‡†ç¡®ç‡æå‡', 'ç›¸å…³ç³»æ•°æå‡(%)', 'åˆæ ¼ç‡æå‡']
                
                colors_bar = ['red' if x < 0 else 'green' for x in improvements]
                bars = ax5.bar(improvement_names, improvements, color=colors_bar, alpha=0.7)
                
                ax5.set_title('NWPä¿¡æ¯æ”¹å–„æ•ˆæœ')
                ax5.set_ylabel('æ”¹å–„ç¨‹åº¦')
                ax5.grid(True, alpha=0.3)
                ax5.axhline(y=0, color='black', linestyle='-', alpha=0.5)
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for bar, value in zip(bars, improvements):
                    ax5.text(bar.get_x() + bar.get_width()/2, 
                            bar.get_height() + (0.1 if value >= 0 else -0.3),
                            f'{value:.2f}', ha='center', va='bottom' if value >= 0 else 'top')
                
                plt.setp(ax5.xaxis.get_majorticklabels(), rotation=45, ha='right')
        
        # 6. ç´¯ç§¯è¯¯å·®å¯¹æ¯”
        ax6 = axes[2, 1]
        if 'basic' in model_predictions and 'nwp_enhanced' in model_predictions:
            basic_errors = model_predictions['basic'][daytime_mask] - actual_day
            nwp_errors = model_predictions['nwp_enhanced'][daytime_mask] - actual_day
            
            cumulative_basic = np.cumsum(np.abs(basic_errors))
            cumulative_nwp = np.cumsum(np.abs(nwp_errors))
            
            day_time_index = range(len(basic_errors))
            ax6.plot(day_time_index, cumulative_basic, label='åŸºç¡€æ¨¡å‹ç´¯ç§¯è¯¯å·®', color='red', linewidth=2)
            ax6.plot(day_time_index, cumulative_nwp, label='NWPå¢å¼ºæ¨¡å‹ç´¯ç§¯è¯¯å·®', color='blue', linewidth=2)
            
            ax6.set_title('ç´¯ç§¯ç»å¯¹è¯¯å·®å¯¹æ¯”')
            ax6.set_xlabel('ç™½å¤©æ—¶é—´ç‚¹')
            ax6.set_ylabel('ç´¯ç§¯ç»å¯¹è¯¯å·® (MW)')
            ax6.legend()
            ax6.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(save_dir / f'{station_id}_nwp_comprehensive_evaluation.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… {station_id} NWPç»¼åˆè¯„ä»·å›¾è¡¨å·²ç”Ÿæˆ")
    
    def create_scenario_effectiveness_chart(self, scenarios, station_id, save_dir="results/figures"):
        """åˆ›å»ºåœºæ™¯æœ‰æ•ˆæ€§åˆ†æå›¾è¡¨"""
        self.ensure_chinese_font()
        
        if not scenarios:
            return
        
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'{station_id} NWPä¿¡æ¯åœºæ™¯æœ‰æ•ˆæ€§åˆ†æ', fontsize=16, fontweight='bold')
        
        scenario_names = [scenarios[k]['description'] for k in scenarios.keys()]
        improvements = [scenarios[k]['improvement'] for k in scenarios.keys()]
        sample_counts = [scenarios[k]['sample_count'] for k in scenarios.keys()]
        
        # 1. åœºæ™¯æ”¹å–„æ•ˆæœæŸ±çŠ¶å›¾
        ax1 = axes[0, 0]
        colors = ['green' if x > 0 else 'red' for x in improvements]
        bars = ax1.bar(range(len(scenario_names)), improvements, color=colors, alpha=0.7)
        ax1.set_xticks(range(len(scenario_names)))
        ax1.set_xticklabels(scenario_names, rotation=45, ha='right')
        ax1.set_ylabel('è¯¯å·®æ”¹å–„ (MW)')
        ax1.set_title('å„åœºæ™¯NWPæ”¹å–„æ•ˆæœ')
        ax1.grid(True, alpha=0.3)
        ax1.axhline(y=0, color='black', linestyle='-', alpha=0.5)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, improvements):
            ax1.text(bar.get_x() + bar.get_width()/2, 
                    bar.get_height() + (0.01 if value >= 0 else -0.02),
                    f'{value:.3f}', ha='center', va='bottom' if value >= 0 else 'top', fontsize=9)
        
        # 2. æ ·æœ¬æ•°é‡åˆ†å¸ƒ
        ax2 = axes[0, 1]
        ax2.bar(range(len(scenario_names)), sample_counts, alpha=0.7, color='skyblue')
        ax2.set_xticks(range(len(scenario_names)))
        ax2.set_xticklabels(scenario_names, rotation=45, ha='right')
        ax2.set_ylabel('æ ·æœ¬æ•°é‡')
        ax2.set_title('å„åœºæ™¯æ ·æœ¬æ•°é‡')
        ax2.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, count in enumerate(sample_counts):
            ax2.text(i, count + max(sample_counts) * 0.01, str(count), 
                    ha='center', va='bottom', fontsize=9)
        
        # 3. æ”¹å–„æ•ˆæœvsæ ·æœ¬æ•°é‡æ•£ç‚¹å›¾
        ax3 = axes[1, 0]
        scatter = ax3.scatter(sample_counts, improvements, s=100, alpha=0.7, c=improvements, cmap='RdYlGn')
        ax3.set_xlabel('æ ·æœ¬æ•°é‡')
        ax3.set_ylabel('è¯¯å·®æ”¹å–„ (MW)')
        ax3.set_title('æ”¹å–„æ•ˆæœ vs æ ·æœ¬æ•°é‡')
        ax3.grid(True, alpha=0.3)
        ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)
        
        # æ·»åŠ åœºæ™¯æ ‡ç­¾
        for i, name in enumerate(scenario_names):
            ax3.annotate(name, (sample_counts[i], improvements[i]), 
                        xytext=(5, 5), textcoords='offset points', fontsize=8)
        
        plt.colorbar(scatter, ax=ax3, label='æ”¹å–„ç¨‹åº¦')
        
        # 4. æœ‰æ•ˆæ€§åˆ†ç±»é¥¼å›¾
        ax4 = axes[1, 1]
        positive_count = sum(1 for x in improvements if x > 0)
        negative_count = sum(1 for x in improvements if x <= 0)
        
        if positive_count + negative_count > 0:
            labels = ['æœ‰æ•ˆåœºæ™¯', 'æ— æ•ˆåœºæ™¯']
            sizes = [positive_count, negative_count]
            colors_pie = ['lightgreen', 'lightcoral']
            
            wedges, texts, autotexts = ax4.pie(sizes, labels=labels, colors=colors_pie, 
                                              autopct='%1.1f%%', startangle=90)
            ax4.set_title('åœºæ™¯æœ‰æ•ˆæ€§åˆ†å¸ƒ')
        
        plt.tight_layout()
        plt.savefig(save_dir / f'{station_id}_scenario_effectiveness.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"âœ… {station_id} åœºæ™¯æœ‰æ•ˆæ€§åˆ†æå›¾è¡¨å·²ç”Ÿæˆ")
    
    def create_multi_station_nwp_comparison(self, all_station_metrics, save_dir="results/figures"):
        """åˆ›å»ºå¤šç«™ç‚¹NWPæ•ˆæœå¯¹æ¯”å›¾è¡¨"""
        self.ensure_chinese_font()
        
        save_dir = Path(save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        stations = list(all_station_metrics.keys())
        
        # æå–å„ç«™ç‚¹çš„åŸºç¡€æ¨¡å‹å’ŒNWPå¢å¼ºæ¨¡å‹æŒ‡æ ‡
        basic_metrics = []
        nwp_metrics = []
        effectiveness_levels = []
        
        for station in stations:
            if 'basic' in all_station_metrics[station] and 'nwp_enhanced' in all_station_metrics[station]:
                basic_metrics.append(all_station_metrics[station]['basic'])
                nwp_metrics.append(all_station_metrics[station]['nwp_enhanced'])
                
                # è®¡ç®—æœ‰æ•ˆæ€§ç­‰çº§
                effectiveness = self.analyze_nwp_effectiveness({
                    'basic': all_station_metrics[station]['basic'],
                    'nwp_enhanced': all_station_metrics[station]['nwp_enhanced']
                })
                effectiveness_levels.append(effectiveness.get('effectiveness_level', 'æœªçŸ¥'))
        
        if not basic_metrics:
            print("âš ï¸ æ²¡æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œå¤šç«™ç‚¹å¯¹æ¯”")
            return
        
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        fig.suptitle('å¤šç«™ç‚¹NWPä¿¡æ¯èå…¥æ•ˆæœå¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. RMSEå¯¹æ¯”
        ax1 = axes[0, 0]
        basic_rmse = [m['RMSE'] for m in basic_metrics]
        nwp_rmse = [m['RMSE'] for m in nwp_metrics]
        
        x = np.arange(len(stations))
        width = 0.35
        
        bars1 = ax1.bar(x - width/2, basic_rmse, width, label='åŸºç¡€æ¨¡å‹', alpha=0.7, color='red')
        bars2 = ax1.bar(x + width/2, nwp_rmse, width, label='NWPå¢å¼ºæ¨¡å‹', alpha=0.7, color='blue')
        
        ax1.set_xlabel('ç«™ç‚¹')
        ax1.set_ylabel('RMSE')
        ax1.set_title('RMSEå¯¹æ¯”')
        ax1.set_xticks(x)
        ax1.set_xticklabels(stations)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. å‡†ç¡®ç‡å¯¹æ¯”
        ax2 = axes[0, 1]
        basic_acc = [m['Accuracy'] for m in basic_metrics]
        nwp_acc = [m['Accuracy'] for m in nwp_metrics]
        
        bars3 = ax2.bar(x - width/2, basic_acc, width, label='åŸºç¡€æ¨¡å‹', alpha=0.7, color='red')
        bars4 = ax2.bar(x + width/2, nwp_acc, width, label='NWPå¢å¼ºæ¨¡å‹', alpha=0.7, color='blue')
        
        ax2.set_xlabel('ç«™ç‚¹')
        ax2.set_ylabel('å‡†ç¡®ç‡ (%)')
        ax2.set_title('å‡†ç¡®ç‡å¯¹æ¯”')
        ax2.set_xticks(x)
        ax2.set_xticklabels(stations)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. æ”¹å–„ç¨‹åº¦åˆ†æ
        ax3 = axes[0, 2]
        rmse_improvements = [(basic_rmse[i] - nwp_rmse[i]) / basic_rmse[i] * 100 for i in range(len(stations))]
        acc_improvements = [nwp_acc[i] - basic_acc[i] for i in range(len(stations))]
        
        colors_improve = ['green' if x > 0 else 'red' for x in rmse_improvements]
        bars5 = ax3.bar(stations, rmse_improvements, alpha=0.7, color=colors_improve)
        
        ax3.set_xlabel('ç«™ç‚¹')
        ax3.set_ylabel('RMSEæ”¹å–„ (%)')
        ax3.set_title('RMSEæ”¹å–„ç¨‹åº¦')
        ax3.grid(True, alpha=0.3)
        ax3.axhline(y=0, color='black', linestyle='-', alpha=0.5)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars5, rmse_improvements):
            ax3.text(bar.get_x() + bar.get_width()/2, 
                    bar.get_height() + (0.5 if value >= 0 else -1),
                    f'{value:.1f}%', ha='center', va='bottom' if value >= 0 else 'top')
        
        # 4. ç›¸å…³ç³»æ•°å¯¹æ¯”
        ax4 = axes[1, 0]
        basic_corr = [m['Correlation'] for m in basic_metrics]
        nwp_corr = [m['Correlation'] for m in nwp_metrics]
        
        bars6 = ax4.bar(x - width/2, basic_corr, width, label='åŸºç¡€æ¨¡å‹', alpha=0.7, color='red')
        bars7 = ax4.bar(x + width/2, nwp_corr, width, label='NWPå¢å¼ºæ¨¡å‹', alpha=0.7, color='blue')
        
        ax4.set_xlabel('ç«™ç‚¹')
        ax4.set_ylabel('ç›¸å…³ç³»æ•°')
        ax4.set_title('ç›¸å…³ç³»æ•°å¯¹æ¯”')
        ax4.set_xticks(x)
        ax4.set_xticklabels(stations)
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        # 5. æœ‰æ•ˆæ€§ç­‰çº§åˆ†å¸ƒ
        ax5 = axes[1, 1]
        effectiveness_counts = {}
        for level in effectiveness_levels:
            effectiveness_counts[level] = effectiveness_counts.get(level, 0) + 1
        
        if effectiveness_counts:
            labels = list(effectiveness_counts.keys())
            sizes = list(effectiveness_counts.values())
            colors_pie = ['lightgreen', 'yellow', 'orange', 'lightcoral'][:len(labels)]
            
            wedges, texts, autotexts = ax5.pie(sizes, labels=labels, colors=colors_pie, 
                                              autopct='%1.1f%%', startangle=90)
            ax5.set_title('NWPæœ‰æ•ˆæ€§ç­‰çº§åˆ†å¸ƒ')
        
        # 6. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
        ax6 = axes[1, 2]
        ax6 = plt.subplot(2, 3, 6, projection='polar')
        
        # è®¡ç®—å¹³å‡æ€§èƒ½
        avg_basic_metrics = {
            'RMSE': np.mean(basic_rmse),
            'Accuracy': np.mean(basic_acc),
            'Correlation': np.mean(basic_corr),
            'MAE': np.mean([m['MAE'] for m in basic_metrics]),
            'Qualification_Rate': np.mean([m['Qualification_Rate'] for m in basic_metrics])
        }
        
        avg_nwp_metrics = {
            'RMSE': np.mean(nwp_rmse),
            'Accuracy': np.mean(nwp_acc),
            'Correlation': np.mean(nwp_corr),
            'MAE': np.mean([m['MAE'] for m in nwp_metrics]),
            'Qualification_Rate': np.mean([m['Qualification_Rate'] for m in nwp_metrics])
        }
        
        categories = ['å‡†ç¡®ç‡', 'åˆæ ¼ç‡', 'ç›¸å…³ç³»æ•°', 'RMSE(å)', 'MAE(å)']
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)
        angles = np.concatenate((angles, [angles[0]]))
        
        basic_values = [
            avg_basic_metrics['Accuracy'],
            avg_basic_metrics['Qualification_Rate'],
            avg_basic_metrics['Correlation'] * 100,
            (1 - avg_basic_metrics['RMSE']) * 100,
            (1 - avg_basic_metrics['MAE']) * 100
        ]
        basic_values += basic_values[:1]
        
        nwp_values = [
            avg_nwp_metrics['Accuracy'],
            avg_nwp_metrics['Qualification_Rate'],
            avg_nwp_metrics['Correlation'] * 100,
            (1 - avg_nwp_metrics['RMSE']) * 100,
            (1 - avg_nwp_metrics['MAE']) * 100
        ]
        nwp_values += nwp_values[:1]
        
        ax6.plot(angles, basic_values, 'o-', linewidth=2, label='åŸºç¡€æ¨¡å‹å¹³å‡', color='red')
        ax6.fill(angles, basic_values, alpha=0.25, color='red')
        ax6.plot(angles, nwp_values, 'o-', linewidth=2, label='NWPå¢å¼ºæ¨¡å‹å¹³å‡', color='blue')
        ax6.fill(angles, nwp_values, alpha=0.25, color='blue')
        
        ax6.set_xticks(angles[:-1])
        ax6.set_xticklabels(categories)
        ax6.set_ylim(0, 100)
        ax6.set_title('å¹³å‡æ€§èƒ½é›·è¾¾å›¾', pad=20)
        ax6.legend()
        ax6.grid(True)
        
        plt.tight_layout()
        plt.savefig(save_dir / 'multi_station_nwp_comparison.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print("âœ… å¤šç«™ç‚¹NWPå¯¹æ¯”åˆ†æå›¾è¡¨å·²ç”Ÿæˆ")

def evaluate_nwp_predictions():
    """è¯„ä¼°NWPé¢„æµ‹ç»“æœ"""
    print("ğŸ” å¼€å§‹è¯„ä¼°NWPé¢„æµ‹ç»“æœ...")
    
    stations = ['station00', 'station04', 'station05', 'station09']
    all_station_metrics = {}
    
    # å¼€æœºå®¹é‡è®¾å®š
    capacities = {
        'station00': 6.628,
        'station04': 32.122,
        'station05': 42.142,
        'station09': 14.454
    }
    
    for station in stations:
        try:
            print(f"\n{'='*20} è¯„ä¼° {station} {'='*20}")
            
            # è¯»å–NWPé¢„æµ‹ç»“æœ
            results_file = f'results/{station}_nwp_prediction_results.csv'
            if not Path(results_file).exists():
                print(f"âŒ æ‰¾ä¸åˆ° {station} çš„NWPé¢„æµ‹ç»“æœæ–‡ä»¶")
                continue
            
            results_df = pd.read_csv(results_file)
            actual_power = results_df['actual_power'].values
            
            # æå–å„æ¨¡å‹çš„é¢„æµ‹ç»“æœ
            model_predictions = {}
            for col in results_df.columns:
                if col.endswith('_prediction'):
                    model_name = col.replace('_prediction', '')
                    model_predictions[model_name] = results_df[col].values
            
            if not model_predictions:
                print(f"âŒ {station} æ²¡æœ‰æ‰¾åˆ°æ¨¡å‹é¢„æµ‹ç»“æœ")
                continue
            
            # åˆ›å»ºè¯„ä»·å™¨
            evaluator = NWPPowerPredictionEvaluator(capacities[station])
            
            # è®¡ç®—å„æ¨¡å‹çš„è¯„ä»·æŒ‡æ ‡
            all_metrics = evaluator.compare_models(actual_power, model_predictions, list(model_predictions.keys()))
            all_station_metrics[station] = all_metrics
            
            # åˆ†æNWPæœ‰æ•ˆæ€§
            effectiveness_analysis = evaluator.analyze_nwp_effectiveness(all_metrics)
            
            # æ‰“å°è¯„ä»·ç»“æœ
            print(f"\nğŸ“Š {station} æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
            print("="*60)
            for model_name, metrics in all_metrics.items():
                print(f"\n{model_name.upper()} æ¨¡å‹:")
                print(f"  RMSE: {metrics['RMSE']:.6f}")
                print(f"  MAE: {metrics['MAE']:.6f}")
                print(f"  ç›¸å…³ç³»æ•°: {metrics['Correlation']:.4f}")
                print(f"  å‡†ç¡®ç‡: {metrics['Accuracy']:.2f}%")
                print(f"  åˆæ ¼ç‡: {metrics['Qualification_Rate']:.2f}%")
            
            if effectiveness_analysis:
                print(f"\nğŸ¯ NWPæœ‰æ•ˆæ€§åˆ†æ:")
                print(f"  RMSEæ”¹å–„: {effectiveness_analysis['rmse_improvement']:.2f}%")
                print(f"  å‡†ç¡®ç‡æå‡: {effectiveness_analysis['accuracy_improvement']:.2f}ä¸ªç™¾åˆ†ç‚¹")
                print(f"  æœ‰æ•ˆæ€§ç­‰çº§: {effectiveness_analysis['effectiveness_level']}")
            
            # åˆ›å»ºå¯è§†åŒ–
            evaluator.create_nwp_comparison_visualization(
                actual_power, model_predictions, station
            )
            
            # ä¿å­˜è¯¦ç»†è¯„ä»·æŠ¥å‘Š
            save_nwp_evaluation_report(station, all_metrics, effectiveness_analysis, 
                                     capacities[station], actual_power, model_predictions)
            
        except Exception as e:
            print(f"âŒ è¯„ä¼° {station} æ—¶å‡ºé”™: {str(e)}")
            continue
    
    # åˆ›å»ºå¤šç«™ç‚¹å¯¹æ¯”
    if all_station_metrics:
        evaluator = NWPPowerPredictionEvaluator(1.0)  # ä¸´æ—¶åˆ›å»ºç”¨äºå¤šç«™ç‚¹å¯¹æ¯”
        evaluator.create_multi_station_nwp_comparison(all_station_metrics)
        create_nwp_comprehensive_report(all_station_metrics)
    
    print(f"\nğŸ‰ NWPé¢„æµ‹ç»“æœè¯„ä¼°å®Œæˆï¼")
    return all_station_metrics

def save_nwp_evaluation_report(station_id, all_metrics, effectiveness_analysis, capacity, actual_power, model_predictions):
    """ä¿å­˜NWPè¯„ä»·æŠ¥å‘Š"""
    
    report = f"""
# {station_id} NWPä¿¡æ¯èå…¥å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹è¯„ä»·æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- **ç«™ç‚¹**: {station_id}
- **å¼€æœºå®¹é‡**: {capacity:.3f} MW
- **è¯„ä¼°æ¨¡å‹æ•°**: {len(all_metrics)}
- **å®é™…åŠŸç‡å‡å€¼**: {actual_power[actual_power > 0].mean():.3f} MW
- **å®é™…åŠŸç‡æœ€å¤§å€¼**: {actual_power.max():.3f} MW

## æ¨¡å‹æ€§èƒ½å¯¹æ¯”

"""
    
    for model_name, metrics in all_metrics.items():
        report += f"""
### {model_name.upper()} æ¨¡å‹
- **RMSE**: {metrics['RMSE']:.6f}
- **MAE**: {metrics['MAE']:.6f}
- **å¹³å‡è¯¯å·® (ME)**: {metrics['ME']:.6f}
- **ç›¸å…³ç³»æ•°**: {metrics['Correlation']:.6f}
- **å‡†ç¡®ç‡**: {metrics['Accuracy']:.2f}%
- **åˆæ ¼ç‡**: {metrics['Qualification_Rate']:.2f}%
- **MAPE**: {metrics['MAPE']:.2f}%
- **æ ·æœ¬æ•°**: {metrics['Sample_Count']}

"""
    
    if effectiveness_analysis:
        report += f"""
## NWPä¿¡æ¯æœ‰æ•ˆæ€§åˆ†æ

### æ”¹å–„æ•ˆæœ
- **RMSEæ”¹å–„**: {effectiveness_analysis['rmse_improvement']:.2f}%
- **MAEæ”¹å–„**: {effectiveness_analysis['mae_improvement']:.2f}%
- **å‡†ç¡®ç‡æå‡**: {effectiveness_analysis['accuracy_improvement']:.2f}ä¸ªç™¾åˆ†ç‚¹
- **ç›¸å…³ç³»æ•°æå‡**: {effectiveness_analysis['correlation_improvement']:.4f}
- **åˆæ ¼ç‡æå‡**: {effectiveness_analysis['qualification_improvement']:.2f}ä¸ªç™¾åˆ†ç‚¹

### æœ‰æ•ˆæ€§è¯„ä»·
- **ç­‰çº§**: {effectiveness_analysis['effectiveness_level']}

"""
        
        # æ ¹æ®æœ‰æ•ˆæ€§ç­‰çº§ç»™å‡ºå»ºè®®
        if effectiveness_analysis['effectiveness_level'] == "æ˜¾è‘—æœ‰æ•ˆ":
            recommendation = "å¼ºçƒˆå»ºè®®åœ¨å®é™…åº”ç”¨ä¸­é‡‡ç”¨NWPå¢å¼ºæ¨¡å‹ï¼Œå¯æ˜¾è‘—æé«˜é¢„æµ‹ç²¾åº¦ã€‚"
        elif effectiveness_analysis['effectiveness_level'] == "æœ‰æ•ˆ":
            recommendation = "å»ºè®®åœ¨å®é™…åº”ç”¨ä¸­é‡‡ç”¨NWPå¢å¼ºæ¨¡å‹ï¼Œå¯æœ‰æ•ˆæé«˜é¢„æµ‹ç²¾åº¦ã€‚"
        elif effectiveness_analysis['effectiveness_level'] == "è½»å¾®æœ‰æ•ˆ":
            recommendation = "å¯è€ƒè™‘åœ¨ç‰¹å®šåœºæ™¯ä¸‹ä½¿ç”¨NWPä¿¡æ¯ï¼Œä½†æ”¹å–„æ•ˆæœæœ‰é™ã€‚"
        else:
            recommendation = "ä¸å»ºè®®ä½¿ç”¨å½“å‰çš„NWPä¿¡æ¯ï¼Œå¯èƒ½éœ€è¦ä¼˜åŒ–æ•°æ®è´¨é‡æˆ–ç‰¹å¾å·¥ç¨‹æ–¹æ³•ã€‚"
        
        report += f"""
### åº”ç”¨å»ºè®®
{recommendation}

"""
    
    report += f"""
## æ¨¡å‹æ’å

### æŒ‰RMSEæ’åºï¼ˆè¶Šå°è¶Šå¥½ï¼‰
"""
    
    sorted_by_rmse = sorted(all_metrics.items(), key=lambda x: x[1]['RMSE'])
    for i, (model_name, metrics) in enumerate(sorted_by_rmse, 1):
        report += f"{i}. {model_name}: {metrics['RMSE']:.6f}\n"
    
    report += f"""
### æŒ‰å‡†ç¡®ç‡æ’åºï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
"""
    
    sorted_by_accuracy = sorted(all_metrics.items(), key=lambda x: x[1]['Accuracy'], reverse=True)
    for i, (model_name, metrics) in enumerate(sorted_by_accuracy, 1):
        report += f"{i}. {model_name}: {metrics['Accuracy']:.2f}%\n"
    
    report += f"""
---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    # ä¿å­˜æŠ¥å‘Š
    with open(f'results/{station_id}_nwp_evaluation_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… NWPè¯„ä»·æŠ¥å‘Šå·²ä¿å­˜: results\\{station_id}_nwp_evaluation_report.md")

def create_nwp_comprehensive_report(all_station_metrics):
    """åˆ›å»ºNWPç»¼åˆå¯¹æ¯”æŠ¥å‘Š"""
    print(f"\n{'='*80}")
    print("ğŸ“Š NWPä¿¡æ¯èå…¥æ•ˆæœç»¼åˆå¯¹æ¯”æŠ¥å‘Š")
    print("="*80)
    
    # ç»Ÿè®¡æœ‰æ•ˆæ€§
    effectiveness_stats = {}
    improvement_stats = []
    
    for station, metrics in all_station_metrics.items():
        if 'basic' in metrics and 'nwp_enhanced' in metrics:
            evaluator = NWPPowerPredictionEvaluator(1.0)
            effectiveness = evaluator.analyze_nwp_effectiveness(metrics)
            
            if effectiveness:
                level = effectiveness['effectiveness_level']
                effectiveness_stats[level] = effectiveness_stats.get(level, 0) + 1
                improvement_stats.append({
                    'station': station,
                    'rmse_improvement': effectiveness['rmse_improvement'],
                    'accuracy_improvement': effectiveness['accuracy_improvement'],
                    'effectiveness_level': level
                })
                
                print(f"{station}: {level} (RMSEæ”¹å–„: {effectiveness['rmse_improvement']:.2f}%)")
    
    print(f"\nğŸ“ˆ æœ‰æ•ˆæ€§ç»Ÿè®¡:")
    for level, count in effectiveness_stats.items():
        print(f"  {level}: {count}ä¸ªç«™ç‚¹")
    
    # è®¡ç®—å¹³å‡æ”¹å–„æ•ˆæœ
    if improvement_stats:
        avg_rmse_improvement = np.mean([s['rmse_improvement'] for s in improvement_stats])
        avg_accuracy_improvement = np.mean([s['accuracy_improvement'] for s in improvement_stats])
        
        print(f"\nğŸ“Š å¹³å‡æ”¹å–„æ•ˆæœ:")
        print(f"  å¹³å‡RMSEæ”¹å–„: {avg_rmse_improvement:.2f}%")
        print(f"  å¹³å‡å‡†ç¡®ç‡æå‡: {avg_accuracy_improvement:.2f}ä¸ªç™¾åˆ†ç‚¹")
    
    # ä¿å­˜ç»¼åˆæŠ¥å‘Š
    report = f"""
# NWPä¿¡æ¯èå…¥å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹ç»¼åˆåˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è¿°
æœ¬æŠ¥å‘Šå…¨é¢åˆ†æäº†NWPï¼ˆæ•°å€¼å¤©æ°”é¢„æŠ¥ï¼‰ä¿¡æ¯å¯¹å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹ç²¾åº¦çš„å½±å“ï¼ŒåŒ…æ‹¬å¤šä¸ªæ¨¡å‹çš„å¯¹æ¯”å’Œä¸åŒåœºæ™¯ä¸‹çš„æœ‰æ•ˆæ€§åˆ†æã€‚

## ç«™ç‚¹åˆ†æç»“æœ

"""
    
    for station, metrics in all_station_metrics.items():
        report += f"""
### {station}
"""
        
        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨æ ¼
        report += "| æ¨¡å‹ | RMSE | MAE | ç›¸å…³ç³»æ•° | å‡†ç¡®ç‡(%) | åˆæ ¼ç‡(%) |\n"
        report += "|------|------|-----|----------|-----------|----------|\n"
        
        for model_name, model_metrics in metrics.items():
            report += f"| {model_name} | {model_metrics['RMSE']:.6f} | {model_metrics['MAE']:.6f} | {model_metrics['Correlation']:.4f} | {model_metrics['Accuracy']:.2f} | {model_metrics['Qualification_Rate']:.2f} |\n"
        
        # NWPæœ‰æ•ˆæ€§åˆ†æ
        if 'basic' in metrics and 'nwp_enhanced' in metrics:
            evaluator = NWPPowerPredictionEvaluator(1.0)
            effectiveness = evaluator.analyze_nwp_effectiveness(metrics)
            
            if effectiveness:
                report += f"""
**NWPæœ‰æ•ˆæ€§**: {effectiveness['effectiveness_level']}
- RMSEæ”¹å–„: {effectiveness['rmse_improvement']:.2f}%
- å‡†ç¡®ç‡æå‡: {effectiveness['accuracy_improvement']:.2f}ä¸ªç™¾åˆ†ç‚¹

"""
    
    report += f"""
## æ€»ä½“ç»“è®º

### NWPä¿¡æ¯æœ‰æ•ˆæ€§ç»Ÿè®¡
"""
    
    for level, count in effectiveness_stats.items():
        report += f"- **{level}**: {count}ä¸ªç«™ç‚¹\n"
    
    if improvement_stats:
        report += f"""
### å¹³å‡æ”¹å–„æ•ˆæœ
- **å¹³å‡RMSEæ”¹å–„**: {avg_rmse_improvement:.2f}%
- **å¹³å‡å‡†ç¡®ç‡æå‡**: {avg_accuracy_improvement:.2f}ä¸ªç™¾åˆ†ç‚¹

### æœ€ä½³æ”¹å–„ç«™ç‚¹
"""
        
        # æŒ‰RMSEæ”¹å–„æ’åº
        best_stations = sorted(improvement_stats, key=lambda x: x['rmse_improvement'], reverse=True)
        for i, station_data in enumerate(best_stations[:3], 1):
            report += f"{i}. {station_data['station']}: RMSEæ”¹å–„ {station_data['rmse_improvement']:.2f}%\n"
    
    report += f"""
### åº”ç”¨å»ºè®®

1. **æ˜¾è‘—æœ‰æ•ˆç«™ç‚¹**: å¼ºçƒˆå»ºè®®åœ¨å®é™…åº”ç”¨ä¸­å…¨é¢é‡‡ç”¨NWPå¢å¼ºæ¨¡å‹
2. **æœ‰æ•ˆç«™ç‚¹**: å»ºè®®åœ¨æ—¥å¸¸é¢„æµ‹ä¸­ä½¿ç”¨NWPä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯åœ¨ç‰¹å®šå¤©æ°”æ¡ä»¶ä¸‹
3. **è½»å¾®æœ‰æ•ˆç«™ç‚¹**: å¯åœ¨å…³é”®æ—¶æ®µæˆ–ç‰¹æ®Šå¤©æ°”æ¡ä»¶ä¸‹é€‰æ‹©æ€§ä½¿ç”¨NWPä¿¡æ¯
4. **æ— æ•ˆç«™ç‚¹**: éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–NWPæ•°æ®è´¨é‡ã€ç‰¹å¾å·¥ç¨‹æ–¹æ³•æˆ–æ¨¡å‹ç»“æ„

### æŠ€æœ¯æ”¹è¿›æ–¹å‘

1. **æ•°æ®è´¨é‡ä¼˜åŒ–**: æé«˜NWPæ•°æ®çš„æ—¶ç©ºåˆ†è¾¨ç‡å’Œå‡†ç¡®æ€§
2. **ç‰¹å¾å·¥ç¨‹æ”¹è¿›**: å¼€å‘æ›´æœ‰æ•ˆçš„NWPç‰¹å¾ç»„åˆå’Œå˜æ¢æ–¹æ³•
3. **æ¨¡å‹ç»“æ„ä¼˜åŒ–**: æ¢ç´¢æ·±åº¦å­¦ä¹ ç­‰æ›´å…ˆè¿›çš„èåˆæ–¹æ³•
4. **åœºæ™¯åŒ–åº”ç”¨**: é’ˆå¯¹ä¸åŒå¤©æ°”æ¡ä»¶å’Œæ—¶é—´æ®µä¼˜åŒ–NWPä¿¡æ¯çš„ä½¿ç”¨ç­–ç•¥

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    with open('results/nwp_comprehensive_evaluation_report.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… NWPç»¼åˆè¯„ä»·æŠ¥å‘Šå·²ä¿å­˜: results/nwp_comprehensive_evaluation_report.md")

if __name__ == "__main__":
    # è¯„ä¼°NWPé¢„æµ‹ç»“æœ
    metrics = evaluate_nwp_predictions() 