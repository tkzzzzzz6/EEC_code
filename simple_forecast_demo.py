# ç®€åŒ–ç‰ˆå…‰ä¼åŠŸç‡é¢„æµ‹æ¼”ç¤º
"""
é—®é¢˜2è§£å†³æ–¹æ¡ˆæ¼”ç¤ºï¼šåŸºäºå†å²åŠŸç‡çš„å…‰ä¼ç”µç«™æ—¥å‰å‘ç”µåŠŸç‡é¢„æµ‹

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬ï¼Œå±•ç¤ºæ ¸å¿ƒé¢„æµ‹é€»è¾‘ï¼Œé¿å…å¤æ‚çš„ä¾èµ–é—®é¢˜
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

# ç®€åŒ–çš„ä¸­æ–‡å­—ä½“è®¾ç½®
try:
    import matplotlib as mpl
    font_path = 'C:/Windows/Fonts/simhei.ttf'
    mpl.font_manager.fontManager.addfont(font_path)  
    mpl.rc('font', family='simhei')
except:
    print("âš ï¸ ä¸­æ–‡å­—ä½“è®¾ç½®å¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤å­—ä½“")

warnings.filterwarnings('ignore')

class SimplePowerForecaster:
    """ç®€åŒ–ç‰ˆå…‰ä¼åŠŸç‡é¢„æµ‹å™¨"""
    
    def __init__(self, station_id: str, data_dir: str = "../PVODdatasets_v1.0"):
        self.station_id = station_id
        self.data_dir = Path(data_dir)
        self.models = {}
        self.scalers = {}
        self.forecast_horizon = 7 * 24 * 4  # 7å¤© * 24å°æ—¶ * 4ä¸ª15åˆ†é’Ÿ
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path("results")
        self.output_dir.mkdir(exist_ok=True)
        
        print(f"ğŸš€ åˆå§‹åŒ– {station_id} ç®€åŒ–é¢„æµ‹æ¨¡å‹")
    
    def load_and_preprocess_data(self) -> pd.DataFrame:
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        print(f"ğŸ“Š åŠ è½½ {self.station_id} æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        file_path = self.data_dir / f"{self.station_id}.csv"
        df = pd.read_csv(file_path)
        
        # æ—¶é—´å¤„ç†
        df['date_time'] = pd.to_datetime(df['date_time'])
        df = df.sort_values('date_time').reset_index(drop=True)
        
        # æ•°æ®æ¸…ç†
        df['power'] = pd.to_numeric(df['power'], errors='coerce')
        df['power'] = df['power'].fillna(0)
        
        # åˆ›å»ºæ—¶é—´ç‰¹å¾
        df['hour'] = df['date_time'].dt.hour
        df['day_of_week'] = df['date_time'].dt.dayofweek
        df['month'] = df['date_time'].dt.month
        df['day_of_year'] = df['date_time'].dt.dayofyear
        
        # åˆ›å»ºæ»åç‰¹å¾
        for lag in [1, 4, 24, 96]:  # 15åˆ†é’Ÿã€1å°æ—¶ã€6å°æ—¶ã€24å°æ—¶å‰
            df[f'power_lag_{lag}'] = df['power'].shift(lag)
        
        # åˆ›å»ºæ»‘åŠ¨çª—å£ç»Ÿè®¡ç‰¹å¾
        for window in [4, 12, 24, 96]:  # 1å°æ—¶ã€3å°æ—¶ã€6å°æ—¶ã€24å°æ—¶çª—å£
            df[f'power_mean_{window}'] = df['power'].rolling(window=window).mean()
            df[f'power_std_{window}'] = df['power'].rolling(window=window).std()
        
        # åˆ é™¤åŒ…å«NaNçš„è¡Œ
        df = df.dropna().reset_index(drop=True)
        
        print(f"âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {df['date_time'].min()} åˆ° {df['date_time'].max()}")
        
        return df
    
    def create_features(self, df: pd.DataFrame) -> np.ndarray:
        """åˆ›å»ºç‰¹å¾çŸ©é˜µ"""
        feature_cols = [
            'hour', 'day_of_week', 'month', 'day_of_year',
            'power_lag_1', 'power_lag_4', 'power_lag_24', 'power_lag_96',
            'power_mean_4', 'power_mean_12', 'power_mean_24', 'power_mean_96',
            'power_std_4', 'power_std_12', 'power_std_24', 'power_std_96'
        ]
        
        # åªä½¿ç”¨å­˜åœ¨çš„åˆ—
        available_cols = [col for col in feature_cols if col in df.columns]
        return df[available_cols].values
    
    def train_models(self, df: pd.DataFrame, train_ratio: float = 0.8):
        """è®­ç»ƒé¢„æµ‹æ¨¡å‹"""
        print(f"\nğŸ¯ å¼€å§‹è®­ç»ƒé¢„æµ‹æ¨¡å‹...")
        
        # åˆ†å‰²æ•°æ®
        split_idx = int(len(df) * train_ratio)
        train_df = df[:split_idx].copy()
        test_df = df[split_idx:].copy()
        
        print(f"ğŸ“Š è®­ç»ƒé›†: {len(train_df)} æ¡è®°å½•")
        print(f"ğŸ“Š æµ‹è¯•é›†: {len(test_df)} æ¡è®°å½•")
        
        # ä¿å­˜æ•°æ®åˆ†å‰²ä¿¡æ¯
        self.train_df = train_df
        self.test_df = test_df
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        X_train = self.create_features(train_df)
        y_train = train_df['power'].values
        
        # æ•°æ®æ ‡å‡†åŒ–
        self.scalers['X'] = MinMaxScaler()
        self.scalers['y'] = MinMaxScaler()
        
        X_train_scaled = self.scalers['X'].fit_transform(X_train)
        y_train_scaled = self.scalers['y'].fit_transform(y_train.reshape(-1, 1)).flatten()
        
        # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
        print("ğŸ”„ è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹...")
        self.models['rf'] = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            n_jobs=-1
        )
        self.models['rf'].fit(X_train_scaled, y_train_scaled)
        
        # è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹
        print("ğŸ”„ è®­ç»ƒçº¿æ€§å›å½’æ¨¡å‹...")
        self.models['lr'] = LinearRegression()
        self.models['lr'].fit(X_train_scaled, y_train_scaled)
        
        # ç®€å•ç§»åŠ¨å¹³å‡æ¨¡å‹
        print("ğŸ”„ åˆ›å»ºç§»åŠ¨å¹³å‡æ¨¡å‹...")
        self.models['ma'] = {
            'window': 96,  # 24å°æ—¶çª—å£
            'data': train_df['power'].values
        }
        
        print(f"âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼ŒæˆåŠŸè®­ç»ƒ {len(self.models)} ä¸ªæ¨¡å‹")
    
    def predict_single_step(self, last_data: pd.DataFrame, model_name: str) -> float:
        """å•æ­¥é¢„æµ‹"""
        if model_name == 'ma':
            # ç§»åŠ¨å¹³å‡é¢„æµ‹
            window = self.models['ma']['window']
            recent_data = self.models['ma']['data'][-window:]
            return np.mean(recent_data)
        
        # æœºå™¨å­¦ä¹ æ¨¡å‹é¢„æµ‹
        X = self.create_features(last_data)
        if len(X) == 0:
            return 0.0
        
        X_scaled = self.scalers['X'].transform(X[-1:])
        y_pred_scaled = self.models[model_name].predict(X_scaled)[0]
        y_pred = self.scalers['y'].inverse_transform([[y_pred_scaled]])[0, 0]
        
        return max(y_pred, 0)  # ç¡®ä¿éè´Ÿ
    
    def multi_step_forecast(self, steps: int) -> dict:
        """å¤šæ­¥é¢„æµ‹"""
        print(f"\nğŸ”® å¼€å§‹7å¤©é¢„æµ‹ ({steps} ä¸ªæ—¶é—´ç‚¹)...")
        
        predictions = {}
        
        # è·å–æœ€åçš„æ•°æ®ä½œä¸ºèµ·ç‚¹
        last_data = self.train_df.copy()
        
        for model_name in ['rf', 'lr', 'ma']:
            model_predictions = []
            current_data = last_data.copy()
            
            for step in range(steps):
                # é¢„æµ‹ä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹
                pred = self.predict_single_step(current_data, model_name)
                model_predictions.append(pred)
                
                # æ›´æ–°æ•°æ®ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œåªæ›´æ–°åŠŸç‡å€¼ï¼‰
                if len(current_data) > 0:
                    # åˆ›å»ºæ–°çš„æ—¶é—´ç‚¹
                    last_time = current_data['date_time'].iloc[-1]
                    new_time = last_time + timedelta(minutes=15)
                    
                    # åˆ›å»ºæ–°è¡Œ
                    new_row = current_data.iloc[-1:].copy()
                    new_row['date_time'] = new_time
                    new_row['power'] = pred
                    new_row['hour'] = new_time.hour
                    new_row['day_of_week'] = new_time.dayofweek
                    new_row['month'] = new_time.month
                    new_row['day_of_year'] = new_time.dayofyear
                    
                    # æ›´æ–°æ»åç‰¹å¾
                    for lag in [1, 4, 24, 96]:
                        if len(current_data) >= lag:
                            new_row[f'power_lag_{lag}'] = current_data['power'].iloc[-lag]
                    
                    # æ·»åŠ åˆ°æ•°æ®ä¸­
                    current_data = pd.concat([current_data, new_row], ignore_index=True)
                    
                    # ä¿æŒæ•°æ®é•¿åº¦ä¸è¦å¤ªé•¿
                    if len(current_data) > 1000:
                        current_data = current_data.iloc[-500:].reset_index(drop=True)
            
            predictions[model_name] = np.array(model_predictions)
        
        # é›†æˆé¢„æµ‹
        valid_predictions = [pred for pred in predictions.values() if len(pred) > 0]
        if valid_predictions:
            predictions['ensemble'] = np.mean(valid_predictions, axis=0)
        
        print(f"âœ… é¢„æµ‹å®Œæˆï¼Œç”Ÿæˆ {len(predictions)} ç»„é¢„æµ‹ç»“æœ")
        
        return predictions
    
    def evaluate_predictions(self, predictions: dict) -> dict:
        """è¯„ä¼°é¢„æµ‹ç»“æœ"""
        if len(self.test_df) == 0:
            print("âš ï¸ æ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œè·³è¿‡è¯„ä¼°")
            return {}
        
        print(f"\nğŸ“Š è¯„ä¼°é¢„æµ‹ç»“æœ...")
        
        # è·å–æµ‹è¯•é›†çœŸå®å€¼
        test_steps = min(len(self.test_df), self.forecast_horizon)
        y_true = self.test_df['power'].values[:test_steps]
        
        evaluation_results = {}
        
        for model_name, y_pred in predictions.items():
            if len(y_pred) == 0:
                continue
            
            # æˆªå–ç›¸åŒé•¿åº¦
            pred_steps = min(len(y_pred), test_steps)
            y_pred_eval = y_pred[:pred_steps]
            y_true_eval = y_true[:pred_steps]
            
            # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
            mae = mean_absolute_error(y_true_eval, y_pred_eval)
            mse = mean_squared_error(y_true_eval, y_pred_eval)
            rmse = np.sqrt(mse)
            
            # è®¡ç®—MAPE
            mask = y_true_eval != 0
            if np.any(mask):
                mape = np.mean(np.abs((y_true_eval[mask] - y_pred_eval[mask]) / y_true_eval[mask])) * 100
            else:
                mape = float('inf')
            
            # è®¡ç®—RÂ²
            r2 = r2_score(y_true_eval, y_pred_eval)
            
            evaluation_results[model_name] = {
                'MAE': mae,
                'MSE': mse,
                'RMSE': rmse,
                'MAPE': mape,
                'R2': r2
            }
            
            print(f"{model_name:10} - MAE: {mae:.4f}, RMSE: {rmse:.4f}, MAPE: {mape:.2f}%, RÂ²: {r2:.4f}")
        
        return evaluation_results
    
    def save_results(self, predictions: dict, evaluation: dict):
        """ä¿å­˜ç»“æœ"""
        print(f"\nğŸ’¾ ä¿å­˜é¢„æµ‹ç»“æœ...")
        
        # åˆ›å»ºæ—¶é—´ç´¢å¼•
        last_time = self.train_df['date_time'].iloc[-1]
        future_times = pd.date_range(
            start=last_time + timedelta(minutes=15),
            periods=self.forecast_horizon,
            freq='15T'
        )
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        results_df = pd.DataFrame({'date_time': future_times})
        
        for model_name, pred in predictions.items():
            if len(pred) > 0:
                results_df[f'predicted_power_{model_name}'] = pred[:len(future_times)]
        
        # å¦‚æœæœ‰æµ‹è¯•æ•°æ®ï¼Œä¹Ÿä¿å­˜çœŸå®å€¼
        if len(self.test_df) > 0:
            test_steps = min(len(self.test_df), len(future_times))
            results_df.loc[:test_steps-1, 'actual_power'] = self.test_df['power'].values[:test_steps]
        
        # ä¿å­˜åˆ°CSV
        output_file = self.output_dir / f"{self.station_id}_simple_forecast.csv"
        results_df.to_csv(output_file, index=False)
        print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        if evaluation:
            eval_df = pd.DataFrame(evaluation).T
            eval_file = self.output_dir / f"{self.station_id}_simple_evaluation.csv"
            eval_df.to_csv(eval_file)
            print(f"âœ… è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ°: {eval_file}")
        
        return results_df
    
    def plot_results(self, results_df: pd.DataFrame):
        """ç»˜åˆ¶ç»“æœ"""
        print(f"\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        try:
            fig, axes = plt.subplots(2, 2, figsize=(16, 10))
            fig.suptitle(f'{self.station_id} å…‰ä¼åŠŸç‡7å¤©é¢„æµ‹ç»“æœ', fontsize=16, fontweight='bold')
            
            # è·å–é¢„æµ‹åˆ—
            pred_cols = [col for col in results_df.columns if col.startswith('predicted_power_')]
            
            # 1. æ—¶é—´åºåˆ—é¢„æµ‹å›¾
            ax1 = axes[0, 0]
            
            # ç»˜åˆ¶çœŸå®å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
            if 'actual_power' in results_df.columns:
                mask = results_df['actual_power'].notna()
                ax1.plot(results_df.loc[mask, 'date_time'], 
                        results_df.loc[mask, 'actual_power'], 
                        'k-', linewidth=2, label='å®é™…åŠŸç‡', alpha=0.8)
            
            # ç»˜åˆ¶å„æ¨¡å‹é¢„æµ‹
            colors = ['red', 'blue', 'green', 'orange']
            for i, col in enumerate(pred_cols):
                model_name = col.replace('predicted_power_', '')
                ax1.plot(results_df['date_time'], results_df[col], 
                        color=colors[i % len(colors)], linewidth=1.5, 
                        label=f'{model_name}é¢„æµ‹', alpha=0.7)
            
            ax1.set_title('7å¤©åŠŸç‡é¢„æµ‹æ—¶é—´åºåˆ—')
            ax1.set_xlabel('æ—¶é—´')
            ax1.set_ylabel('åŠŸç‡ (MW)')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # 2. é¢„æµ‹ç»Ÿè®¡å¯¹æ¯”
            ax2 = axes[0, 1]
            
            stats_data = []
            for col in pred_cols:
                model_name = col.replace('predicted_power_', '')
                stats_data.append({
                    'æ¨¡å‹': model_name,
                    'å¹³å‡åŠŸç‡': results_df[col].mean(),
                    'æœ€å¤§åŠŸç‡': results_df[col].max(),
                    'æ ‡å‡†å·®': results_df[col].std()
                })
            
            if stats_data:
                stats_df = pd.DataFrame(stats_data)
                x_pos = np.arange(len(stats_df))
                width = 0.25
                
                ax2.bar(x_pos - width, stats_df['å¹³å‡åŠŸç‡'], width, label='å¹³å‡åŠŸç‡', alpha=0.7)
                ax2.bar(x_pos, stats_df['æœ€å¤§åŠŸç‡'], width, label='æœ€å¤§åŠŸç‡', alpha=0.7)
                ax2.bar(x_pos + width, stats_df['æ ‡å‡†å·®'], width, label='æ ‡å‡†å·®', alpha=0.7)
                
                ax2.set_title('æ¨¡å‹é¢„æµ‹ç»Ÿè®¡å¯¹æ¯”')
                ax2.set_xlabel('æ¨¡å‹')
                ax2.set_ylabel('åŠŸç‡ (MW)')
                ax2.set_xticks(x_pos)
                ax2.set_xticklabels(stats_df['æ¨¡å‹'])
                ax2.legend()
                ax2.grid(True, alpha=0.3)
            
            # 3. å°æ—¶å¹³å‡åŠŸç‡
            ax3 = axes[1, 0]
            
            results_df['hour'] = results_df['date_time'].dt.hour
            hourly_stats = results_df.groupby('hour').agg({
                col: 'mean' for col in pred_cols
            }).reset_index()
            
            for col in pred_cols:
                model_name = col.replace('predicted_power_', '')
                ax3.plot(hourly_stats['hour'], hourly_stats[col], 
                        marker='o', linewidth=2, label=f'{model_name}é¢„æµ‹')
            
            ax3.set_title('å°æ—¶å¹³å‡åŠŸç‡å˜åŒ–')
            ax3.set_xlabel('å°æ—¶')
            ax3.set_ylabel('å¹³å‡åŠŸç‡ (MW)')
            ax3.legend()
            ax3.grid(True, alpha=0.3)
            ax3.set_xticks(range(0, 24, 2))
            
            # 4. åŠŸç‡åˆ†å¸ƒ
            ax4 = axes[1, 1]
            
            for col in pred_cols:
                model_name = col.replace('predicted_power_', '')
                ax4.hist(results_df[col], bins=20, alpha=0.6, label=f'{model_name}é¢„æµ‹', density=True)
            
            ax4.set_title('åŠŸç‡åˆ†å¸ƒå¯¹æ¯”')
            ax4.set_xlabel('åŠŸç‡ (MW)')
            ax4.set_ylabel('å¯†åº¦')
            ax4.legend()
            ax4.grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            output_file = self.output_dir / f"{self.station_id}_simple_forecast_analysis.png"
            plt.savefig(output_file, dpi=300, bbox_inches='tight')
            print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜åˆ°: {output_file}")
            plt.close()
            
        except Exception as e:
            print(f"âš ï¸ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ ç®€åŒ–ç‰ˆå…‰ä¼ç”µç«™æ—¥å‰å‘ç”µåŠŸç‡é¢„æµ‹ç³»ç»Ÿ")
    print("=" * 60)
    print("é—®é¢˜2è§£å†³æ–¹æ¡ˆæ¼”ç¤ºï¼šåŸºäºå†å²åŠŸç‡çš„7å¤©é¢„æµ‹æ¨¡å‹")
    print("=" * 60)
    
    # é€‰æ‹©è¦åˆ†æçš„ç«™ç‚¹
    station_id = "station01"
    
    try:
        # åˆå§‹åŒ–é¢„æµ‹å™¨
        forecaster = SimplePowerForecaster(station_id)
        
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        df = forecaster.load_and_preprocess_data()
        
        # è®­ç»ƒæ¨¡å‹
        forecaster.train_models(df)
        
        # è¿›è¡Œ7å¤©é¢„æµ‹
        predictions = forecaster.multi_step_forecast(forecaster.forecast_horizon)
        
        # è¯„ä¼°é¢„æµ‹ç»“æœ
        evaluation = forecaster.evaluate_predictions(predictions)
        
        # ä¿å­˜ç»“æœ
        results_df = forecaster.save_results(predictions, evaluation)
        
        # ç”Ÿæˆå¯è§†åŒ–
        forecaster.plot_results(results_df)
        
        print(f"\nğŸ‰ {station_id} é¢„æµ‹å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: p2/results/")
        
        return forecaster, results_df
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return None, None


if __name__ == "__main__":
    forecaster, results = main() 