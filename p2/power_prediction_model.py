# åŸºäºå†å²åŠŸç‡çš„å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹æ¨¡å‹
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
from datetime import datetime, timedelta
import joblib

# ç®€åŒ–çš„ä¸­æ–‡å­—ä½“è®¾ç½®
import matplotlib as mpl
font_path = 'C:/Windows/Fonts/simhei.ttf'
mpl.font_manager.fontManager.addfont(font_path)  
mpl.rc('font', family='simhei')

warnings.filterwarnings('ignore')

class PowerPredictionModel:
    """åŸºäºå†å²åŠŸç‡çš„å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, data_dir: str = "../PVODdatasets_v1.0"):
        self.data_dir = Path(data_dir)
        self.model = None
        self.feature_names = []
        self.scaler = None
        
    def load_station_data(self, station_id: str) -> pd.DataFrame:
        """åŠ è½½ç«™ç‚¹æ•°æ®"""
        file_path = self.data_dir / f"{station_id}.csv"
        df = pd.read_csv(file_path)
        df['date_time'] = pd.to_datetime(df['date_time'])
        df = df.sort_values('date_time').reset_index(drop=True)
        
        # ç¡®ä¿15åˆ†é’Ÿé—´éš”çš„å®Œæ•´æ—¶é—´åºåˆ—
        df = df.set_index('date_time').resample('15T').mean().reset_index()
        df['power'] = df['power'].fillna(0)  # ç¼ºå¤±åŠŸç‡å€¼å¡«å……ä¸º0
        
        return df
    
    def create_time_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæ—¶é—´ç‰¹å¾ - ä½¿ç”¨UTCæ—¶é—´"""
        df = df.copy()
        
        # åŸºæœ¬æ—¶é—´ç‰¹å¾
        df['hour'] = df['date_time'].dt.hour
        df['minute'] = df['date_time'].dt.minute
        df['day_of_week'] = df['date_time'].dt.dayofweek
        df['day_of_year'] = df['date_time'].dt.dayofyear
        df['month'] = df['date_time'].dt.month
        df['quarter'] = df['date_time'].dt.quarter
        
        # å‘¨æœŸæ€§ç‰¹å¾ï¼ˆæ­£å¼¦ä½™å¼¦ç¼–ç ï¼‰
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['day_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['day_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        
        # 15åˆ†é’Ÿæ—¶æ®µç‰¹å¾
        df['time_slot'] = df['hour'] * 4 + df['minute'] // 15
        df['time_slot_sin'] = np.sin(2 * np.pi * df['time_slot'] / 96)
        df['time_slot_cos'] = np.cos(2 * np.pi * df['time_slot'] / 96)
        
        # ç™½å¤©æ—¶æ®µåˆ¤æ–­ - UTCæ—¶é—´ï¼Œä¸­å›½å…‰ä¼å‘ç”µä¸»è¦åœ¨UTC 22:00-10:00ï¼ˆåŒ—äº¬æ—¶é—´6:00-18:00ï¼‰
        # ç”±äºè·¨è¶Šåˆå¤œï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
        df['is_daytime'] = ((df['hour'] >= 22) | (df['hour'] <= 10)).astype(int)
        
        return df
    
    def create_lag_features(self, df: pd.DataFrame, target_col: str = 'power') -> pd.DataFrame:
        """åˆ›å»ºæ»åç‰¹å¾ï¼ˆåŸºäºå†å²åŠŸç‡ï¼‰"""
        df = df.copy()
        
        # çŸ­æœŸæ»åç‰¹å¾ï¼ˆ1å°æ—¶å†…ï¼‰
        for lag in [1, 2, 3, 4]:  # 15åˆ†é’Ÿ, 30åˆ†é’Ÿ, 45åˆ†é’Ÿ, 1å°æ—¶
            df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)
        
        # ä¸­æœŸæ»åç‰¹å¾ï¼ˆå‡ å°æ—¶å‰ï¼‰
        for lag in [8, 12, 16, 24]:  # 2å°æ—¶, 3å°æ—¶, 4å°æ—¶, 6å°æ—¶
            df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)
        
        # é•¿æœŸæ»åç‰¹å¾ï¼ˆå¤©çº§åˆ«ï¼‰
        for lag in [96, 192, 288, 672]:  # 1å¤©, 2å¤©, 3å¤©, 7å¤©å‰åŒä¸€æ—¶åˆ»
            df[f'{target_col}_lag_{lag}'] = df[target_col].shift(lag)
        
        # æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
        windows = [4, 8, 24, 96]  # 1å°æ—¶, 2å°æ—¶, 6å°æ—¶, 1å¤©
        for window in windows:
            df[f'{target_col}_rolling_mean_{window}'] = df[target_col].rolling(window=window, min_periods=1).mean()
            df[f'{target_col}_rolling_std_{window}'] = df[target_col].rolling(window=window, min_periods=1).std()
            df[f'{target_col}_rolling_max_{window}'] = df[target_col].rolling(window=window, min_periods=1).max()
            df[f'{target_col}_rolling_min_{window}'] = df[target_col].rolling(window=window, min_periods=1).min()
        
        # åŒæ—¶æ®µå†å²ç»Ÿè®¡ç‰¹å¾
        df['hour_minute'] = df['hour'] * 100 + df['minute']
        
        # è®¡ç®—åŒä¸€æ—¶æ®µçš„å†å²å¹³å‡å€¼ï¼ˆè¿‡å»7å¤©ã€14å¤©ã€30å¤©ï¼‰
        for days in [7, 14, 30]:
            periods = days * 96  # æ¯å¤©96ä¸ª15åˆ†é’Ÿæ—¶æ®µ
            df[f'{target_col}_same_time_mean_{days}d'] = (
                df.groupby('hour_minute')[target_col]
                .rolling(window=days, min_periods=1)
                .mean()
                .reset_index(level=0, drop=True)
            )
        
        # å·®åˆ†ç‰¹å¾
        df[f'{target_col}_diff_1'] = df[target_col].diff(1)
        df[f'{target_col}_diff_4'] = df[target_col].diff(4)  # 1å°æ—¶å·®åˆ†
        df[f'{target_col}_diff_96'] = df[target_col].diff(96)  # 1å¤©å·®åˆ†
        
        return df
    
    def prepare_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """å‡†å¤‡æ‰€æœ‰ç‰¹å¾ - åªä½¿ç”¨å†å²åŠŸç‡æ•°æ®ï¼Œåªé¢„æµ‹ç™½å¤©æ—¶æ®µ"""
        print("ğŸ”§ åˆ›å»ºæ—¶é—´ç‰¹å¾...")
        df = self.create_time_features(df)
        
        print("ğŸ”§ åˆ›å»ºæ»åç‰¹å¾...")
        df = self.create_lag_features(df)
        
        # åªä¿ç•™ç™½å¤©æ—¶æ®µçš„æ•°æ®è¿›è¡Œè®­ç»ƒï¼ˆåŠŸç‡>0æˆ–è€…æ˜¯ç™½å¤©æ—¶æ®µï¼‰
        print("ğŸŒ… è¿‡æ»¤ç™½å¤©æ•°æ®...")
        daytime_mask = (df['is_daytime'] == 1) | (df['power'] > 0)
        df_daytime = df[daytime_mask].copy()
        
        print(f"  åŸå§‹æ•°æ®: {len(df):,} æ¡")
        print(f"  ç™½å¤©æ•°æ®: {len(df_daytime):,} æ¡ ({len(df_daytime)/len(df)*100:.1f}%)")
        
        # ç§»é™¤ä¸éœ€è¦çš„åˆ—ï¼Œåªä¿ç•™åŸºäºå†å²åŠŸç‡çš„ç‰¹å¾
        power_feature_cols = [col for col in df_daytime.columns 
                             if col not in ['date_time', 'power', 'hour_minute'] 
                             and ('power_' in col or col in ['hour', 'minute', 'day_of_week', 'month', 
                                                           'hour_sin', 'hour_cos', 'day_sin', 'day_cos', 
                                                           'month_sin', 'month_cos', 'time_slot_sin', 
                                                           'time_slot_cos', 'is_daytime'])]
        
        # ç§»é™¤åŒ…å«NaNçš„è¡Œï¼ˆç”±äºæ»åç‰¹å¾äº§ç”Ÿï¼‰
        df_clean = df_daytime.dropna()
        
        self.feature_names = power_feature_cols
        print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼Œå…±åˆ›å»º {len(power_feature_cols)} ä¸ªåŸºäºå†å²åŠŸç‡çš„ç‰¹å¾")
        print(f"  æœ‰æ•ˆè®­ç»ƒæ•°æ®: {len(df_clean):,} æ¡")
        
        return df_clean
    
    def train_model(self, df: pd.DataFrame, test_size: float = 0.2):
        """è®­ç»ƒXGBoostæ¨¡å‹"""
        print("ğŸš€ å¼€å§‹è®­ç»ƒXGBoostæ¨¡å‹...")
        
        # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
        X = df[self.feature_names]
        y = df['power']
        
        # æ—¶é—´åºåˆ—åˆ†å‰²ï¼ˆä¿æŒæ—¶é—´é¡ºåºï¼‰
        split_idx = int(len(df) * (1 - test_size))
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        print(f"è®­ç»ƒé›†å¤§å°: {len(X_train)}")
        print(f"æµ‹è¯•é›†å¤§å°: {len(X_test)}")
        
        # XGBoostå‚æ•°
        params = {
            'objective': 'reg:squarederror',
            'max_depth': 8,
            'learning_rate': 0.1,
            'n_estimators': 500,
            'subsample': 0.8,
            'colsample_bytree': 0.8,
            'random_state': 42,
            'n_jobs': -1
        }
        
        # è®­ç»ƒæ¨¡å‹
        self.model = xgb.XGBRegressor(**params)
        
        # ç®€åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œç¡®ä¿å…¼å®¹æ€§
        self.model.fit(X_train, y_train, verbose=False)
        
        # é¢„æµ‹
        y_train_pred = self.model.predict(X_train)
        y_test_pred = self.model.predict(X_test)
        
        # è¯„ä¼°
        train_metrics = self.calculate_metrics(y_train, y_train_pred)
        test_metrics = self.calculate_metrics(y_test, y_test_pred)
        
        print(f"\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
        print(f"è®­ç»ƒé›† - MAE: {train_metrics['mae']:.4f}, RMSE: {train_metrics['rmse']:.4f}, RÂ²: {train_metrics['r2']:.4f}")
        print(f"æµ‹è¯•é›† - MAE: {test_metrics['mae']:.4f}, RMSE: {test_metrics['rmse']:.4f}, RÂ²: {test_metrics['r2']:.4f}")
        
        return {
            'train_metrics': train_metrics,
            'test_metrics': test_metrics,
            'X_test': X_test,
            'y_test': y_test,
            'y_test_pred': y_test_pred,
            'test_dates': df['date_time'][split_idx:].reset_index(drop=True)
        }
    
    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡ - é’ˆå¯¹ç™½å¤©åŠŸç‡æ•°æ®"""
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        r2 = r2_score(y_true, y_pred)
        
        # è®¡ç®—MAPEï¼ˆå¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼‰- åªé’ˆå¯¹éé›¶å€¼
        mask = y_true > 0.01  # é¿å…é™¤ä»¥æ¥è¿‘0çš„å€¼
        if mask.sum() > 0:
            mape = np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100
        else:
            mape = 0
        
        return {
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'mape': mape
        }
    
    def predict_future(self, df: pd.DataFrame, forecast_days: int = 7) -> pd.DataFrame:
        """é¢„æµ‹æœªæ¥åŠŸç‡ - ä¼˜åŒ–é€’å½’é¢„æµ‹ç­–ç•¥"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨train_modelæ–¹æ³•")
        
        print(f"ğŸ”® å¼€å§‹é¢„æµ‹æœªæ¥ {forecast_days} å¤©çš„åŠŸç‡...")
        
        # å‡†å¤‡é¢„æµ‹æ•°æ®
        last_date = df['date_time'].max()
        forecast_periods = forecast_days * 96  # æ¯å¤©96ä¸ª15åˆ†é’Ÿæ—¶æ®µ
        
        # åˆ›å»ºæœªæ¥æ—¶é—´åºåˆ—
        future_dates = pd.date_range(
            start=last_date + timedelta(minutes=15),
            periods=forecast_periods,
            freq='15T'
        )
        
        # è®¡ç®—å†å²åŒæ—¶æ®µçš„ç»Ÿè®¡ä¿¡æ¯ï¼Œç”¨äºé¢„æµ‹å€¼çš„åˆç†æ€§æ£€æŸ¥
        df['hour'] = df['date_time'].dt.hour
        df['minute'] = df['date_time'].dt.minute
        df['time_slot'] = df['hour'] * 4 + df['minute'] // 15
        
        # è®¡ç®—æ¯ä¸ªæ—¶æ®µçš„å†å²ç»Ÿè®¡
        historical_stats = df.groupby('time_slot')['power'].agg(['mean', 'std', 'min', 'max']).fillna(0)
        
        # åˆ›å»ºæ‰©å±•æ•°æ®æ¡†ï¼ŒåŒ…å«å†å²æ•°æ®å’Œæœªæ¥æ—¶é—´ç‚¹
        future_df = pd.DataFrame({'date_time': future_dates, 'power': 0.0})
        extended_df = pd.concat([df, future_df], ignore_index=True)
        
        # é¢„å…ˆåˆ›å»ºæ—¶é—´ç‰¹å¾
        extended_df = self.create_time_features(extended_df)
        
        print(f"  å†å²æ•°æ®ç‚¹: {len(df)}")
        print(f"  é¢„æµ‹æ•°æ®ç‚¹: {len(future_df)}")
        
        # é€æ­¥é¢„æµ‹
        predictions = []
        start_idx = len(df)
        
        for i in range(start_idx, len(extended_df)):
            current_time = extended_df.loc[i, 'date_time']
            hour = current_time.hour
            minute = current_time.minute
            time_slot = hour * 4 + minute // 15
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºç™½å¤©æ—¶æ®µ
            is_daytime = (hour >= 22) or (hour <= 10)
            
            if is_daytime:
                try:
                    # é‡æ–°è®¡ç®—å½“å‰æ—¶åˆ»çš„æ»åç‰¹å¾
                    current_extended_df = extended_df[:i+1].copy()
                    current_extended_df = self.create_lag_features(current_extended_df)
                    
                    # è·å–æœ€åä¸€è¡Œçš„ç‰¹å¾
                    if len(current_extended_df) > 0:
                        last_row = current_extended_df.iloc[-1]
                        feature_values = last_row[self.feature_names]
                        
                        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦å®Œæ•´
                        if not feature_values.isna().any():
                            X_current = feature_values.values.reshape(1, -1)
                            pred = self.model.predict(X_current)[0]
                            pred = max(0, pred)  # ç¡®ä¿åŠŸç‡éè´Ÿ
                            
                            # é¢„æµ‹å€¼åˆç†æ€§æ£€æŸ¥å’Œè°ƒæ•´
                            if time_slot in historical_stats.index:
                                hist_mean = historical_stats.loc[time_slot, 'mean']
                                hist_std = historical_stats.loc[time_slot, 'std']
                                hist_max = historical_stats.loc[time_slot, 'max']
                                
                                # å¦‚æœé¢„æµ‹å€¼è¿‡å°ï¼Œä½¿ç”¨å†å²å‡å€¼çš„ä¸€å®šæ¯”ä¾‹
                                if pred < hist_mean * 0.1 and hist_mean > 0.1:
                                    # ä½¿ç”¨å†å²å‡å€¼çš„50%-80%ä½œä¸ºé¢„æµ‹å€¼
                                    pred = hist_mean * np.random.uniform(0.5, 0.8)
                                
                                # å¦‚æœé¢„æµ‹å€¼è¿‡å¤§ï¼Œé™åˆ¶åœ¨å†å²æœ€å¤§å€¼èŒƒå›´å†…
                                elif pred > hist_max * 1.2:
                                    pred = hist_max * np.random.uniform(0.8, 1.0)
                        else:
                            # ç‰¹å¾ä¸å®Œæ•´æ—¶ï¼Œä½¿ç”¨å†å²åŒæ—¶æ®µå¹³å‡å€¼
                            if time_slot in historical_stats.index:
                                hist_mean = historical_stats.loc[time_slot, 'mean']
                                pred = hist_mean * np.random.uniform(0.7, 1.0)
                            else:
                                pred = 0
                    else:
                        pred = 0
                        
                except Exception as e:
                    # é¢„æµ‹å¤±è´¥æ—¶ï¼Œä½¿ç”¨å†å²åŒæ—¶æ®µå¹³å‡å€¼
                    if time_slot in historical_stats.index:
                        hist_mean = historical_stats.loc[time_slot, 'mean']
                        pred = hist_mean * np.random.uniform(0.7, 1.0)
                    else:
                        pred = 0
            else:
                # å¤œé—´æ—¶æ®µç›´æ¥è®¾ä¸º0
                pred = 0
            
            # æ›´æ–°æ‰©å±•æ•°æ®æ¡†ä¸­çš„åŠŸç‡å€¼
            extended_df.loc[i, 'power'] = pred
            predictions.append(pred)
            
            # è¿›åº¦æ˜¾ç¤º
            if (i - start_idx + 1) % 96 == 0:
                day_num = (i - start_idx + 1) // 96
                avg_power = np.mean(predictions[-96:])
                max_power = np.max(predictions[-96:])
                print(f"  å·²å®Œæˆç¬¬ {day_num} å¤©é¢„æµ‹ï¼Œå¹³å‡åŠŸç‡: {avg_power:.3f} MWï¼Œæœ€å¤§åŠŸç‡: {max_power:.3f} MW")
        
        # è¿”å›é¢„æµ‹ç»“æœ
        forecast_df = pd.DataFrame({
            'date_time': future_dates,
            'predicted_power': predictions
        })
        
        # ç»Ÿè®¡ç™½å¤©é¢„æµ‹æƒ…å†µ
        forecast_df['hour'] = forecast_df['date_time'].dt.hour
        daytime_predictions = forecast_df[(forecast_df['hour'] >= 22) | (forecast_df['hour'] <= 10)]
        
        print(f"âœ… é¢„æµ‹å®Œæˆï¼å…±é¢„æµ‹ {len(predictions)} ä¸ªæ—¶é—´ç‚¹")
        print(f"  å…¶ä¸­ç™½å¤©æ—¶æ®µ: {len(daytime_predictions)} ä¸ªï¼Œå¹³å‡åŠŸç‡: {daytime_predictions['predicted_power'].mean():.3f} MW")
        print(f"  å¤œé—´æ—¶æ®µ: {len(predictions) - len(daytime_predictions)} ä¸ªï¼ŒåŠŸç‡å‡ä¸º 0 MW")
        
        # éªŒè¯é¢„æµ‹ç»“æœçš„å¤šæ ·æ€§
        daily_means = []
        for day in range(forecast_days):
            day_start = day * 96
            day_end = (day + 1) * 96
            if day_end <= len(predictions):
                daily_mean = np.mean(predictions[day_start:day_end])
                daily_means.append(daily_mean)
        
        if len(daily_means) > 1:
            daily_variance = np.var(daily_means)
            print(f"  æ¯æ—¥å¹³å‡åŠŸç‡æ–¹å·®: {daily_variance:.6f} (>0è¡¨ç¤ºæœ‰å·®å¼‚)")
            print(f"  æ¯æ—¥å¹³å‡åŠŸç‡èŒƒå›´: {min(daily_means):.3f} - {max(daily_means):.3f} MW")
        
        return forecast_df
    
    def save_model(self, filepath: str):
        """ä¿å­˜æ¨¡å‹"""
        model_data = {
            'model': self.model,
            'feature_names': self.feature_names
        }
        joblib.dump(model_data, filepath)
        print(f"âœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {filepath}")
    
    def load_model(self, filepath: str):
        """åŠ è½½æ¨¡å‹"""
        model_data = joblib.load(filepath)
        self.model = model_data['model']
        self.feature_names = model_data['feature_names']
        print(f"âœ… æ¨¡å‹å·²ä» {filepath} åŠ è½½")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒ åŸºäºå†å²åŠŸç‡çš„å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹ç³»ç»Ÿ")
    print("="*60)
    
    # åˆå§‹åŒ–æ¨¡å‹
    predictor = PowerPredictionModel()
    
    # é€‰æ‹©ç«™ç‚¹è¿›è¡Œåˆ†æ
    station_id = "station01"
    print(f"ğŸ¯ åˆ†æç«™ç‚¹: {station_id}")
    
    # åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½æ•°æ®...")
    df = predictor.load_station_data(station_id)
    print(f"æ•°æ®èŒƒå›´: {df['date_time'].min()} åˆ° {df['date_time'].max()}")
    print(f"æ•°æ®ç‚¹æ•°: {len(df)}")
    
    # å‡†å¤‡ç‰¹å¾
    df_features = predictor.prepare_features(df)
    
    # è®­ç»ƒæ¨¡å‹
    results = predictor.train_model(df_features)
    
    # é¢„æµ‹æœªæ¥7å¤©
    forecast_df = predictor.predict_future(df, forecast_days=7)
    
    # ä¿å­˜ç»“æœ
    output_dir = Path("results")
    output_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜é¢„æµ‹ç»“æœ
    forecast_df.to_csv(output_dir / f"{station_id}_7day_forecast.csv", index=False)
    
    # ä¿å­˜æ¨¡å‹
    predictor.save_model(output_dir / f"{station_id}_xgboost_model.pkl")
    
    print(f"\nğŸ‰ é¢„æµ‹å®Œæˆï¼")
    print(f"ğŸ“ é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°: {output_dir / f'{station_id}_7day_forecast.csv'}")
    print(f"ğŸ¤– æ¨¡å‹å·²ä¿å­˜åˆ°: {output_dir / f'{station_id}_xgboost_model.pkl'}")
    
    return predictor, forecast_df, results


if __name__ == "__main__":
    predictor, forecast_df, results = main() 