# å¤šç«™ç‚¹å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹ç³»ç»Ÿ
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
from pathlib import Path
import warnings
from datetime import datetime, timedelta
import joblib
import time

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

class MultiStationPowerPredictor:
    """å¤šç«™ç‚¹å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹ç³»ç»Ÿ"""
    
    def __init__(self, data_dir: str = "../PVODdatasets_v1.0"):
        self.data_dir = Path(data_dir)
        self.models = {}
        self.results = {}
        self.historical_patterns = {}
        
    def load_station_data(self, station_id: str) -> pd.DataFrame:
        """åŠ è½½ç«™ç‚¹æ•°æ®"""
        file_path = self.data_dir / f"{station_id}.csv"
        df = pd.read_csv(file_path)
        df['date_time'] = pd.to_datetime(df['date_time'])
        df = df.sort_values('date_time').reset_index(drop=True)
        
        # ç¡®ä¿15åˆ†é’Ÿé—´éš”çš„å®Œæ•´æ—¶é—´åºåˆ—
        df = df.set_index('date_time').resample('15T').mean().reset_index()
        df['power'] = df['power'].fillna(0)
        
        return df
    
    def analyze_historical_patterns(self, df: pd.DataFrame, station_id: str):
        """åˆ†æå†å²æ¨¡å¼"""
        df['hour'] = df['date_time'].dt.hour
        df['minute'] = df['date_time'].dt.minute
        df['time_slot'] = df['hour'] * 4 + df['minute'] // 15
        df['day_of_week'] = df['date_time'].dt.dayofweek
        
        # æŒ‰æ—¶æ®µç»Ÿè®¡å†å²æ¨¡å¼
        patterns = {}
        patterns['hourly'] = df.groupby('hour')['power'].agg(['mean', 'std', 'min', 'max']).fillna(0)
        patterns['time_slot'] = df.groupby('time_slot')['power'].agg(['mean', 'std', 'min', 'max']).fillna(0)
        patterns['weekday'] = df.groupby('day_of_week')['power'].agg(['mean', 'std', 'min', 'max']).fillna(0)
        
        # åˆ†ææœ€è¿‘30å¤©çš„æ¨¡å¼å˜åŒ–
        recent_data = df.tail(30 * 96)
        patterns['recent_hourly'] = recent_data.groupby('hour')['power'].agg(['mean', 'std', 'min', 'max']).fillna(0)
        
        # åˆ†æåŠŸç‡å˜åŒ–çš„è¿ç»­æ€§
        df['power_diff'] = df['power'].diff()
        patterns['power_changes'] = {
            'mean': df['power_diff'].mean(),
            'std': df['power_diff'].std(),
            'max_increase': df['power_diff'].max(),
            'max_decrease': df['power_diff'].min()
        }
        
        self.historical_patterns[station_id] = patterns
        
        print(f"  {station_id} å†å²æ¨¡å¼åˆ†æå®Œæˆ")
        print(f"    å¹³å‡åŠŸç‡: {df['power'].mean():.3f} MW")
        print(f"    æœ€å¤§åŠŸç‡: {df['power'].max():.3f} MW")
        print(f"    å³°å€¼æ—¶æ®µ: UTC {patterns['hourly']['mean'].idxmax()}:00")
    
    def create_enhanced_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºå¢å¼ºçš„ç‰¹å¾å·¥ç¨‹"""
        df = df.copy()
        
        # åŸºæœ¬æ—¶é—´ç‰¹å¾
        df['hour'] = df['date_time'].dt.hour
        df['minute'] = df['date_time'].dt.minute
        df['day_of_week'] = df['date_time'].dt.dayofweek
        df['day_of_year'] = df['date_time'].dt.dayofyear
        df['month'] = df['date_time'].dt.month
        
        # æ—¶æ®µç‰¹å¾
        df['time_slot'] = df['hour'] * 4 + df['minute'] // 15
        
        # å‘¨æœŸæ€§ç‰¹å¾
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['time_slot_sin'] = np.sin(2 * np.pi * df['time_slot'] / 96)
        df['time_slot_cos'] = np.cos(2 * np.pi * df['time_slot'] / 96)
        
        # ç™½å¤©åˆ¤æ–­ - UTCæ—¶é—´
        df['is_daytime'] = ((df['hour'] >= 22) | (df['hour'] <= 10)).astype(int)
        
        # å¢å¼ºçš„æ»åç‰¹å¾
        lag_periods = [1, 2, 3, 4, 8, 12, 24, 48, 96, 192, 288, 672]
        for lag in lag_periods:
            df[f'power_lag_{lag}'] = df['power'].shift(lag)
        
        # æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
        windows = [4, 8, 12, 24, 48, 96]
        for window in windows:
            df[f'power_rolling_mean_{window}'] = df['power'].rolling(window=window, min_periods=1).mean()
            df[f'power_rolling_std_{window}'] = df['power'].rolling(window=window, min_periods=1).std()
            df[f'power_rolling_max_{window}'] = df['power'].rolling(window=window, min_periods=1).max()
            df[f'power_rolling_min_{window}'] = df['power'].rolling(window=window, min_periods=1).min()
        
        # åŒæ—¶æ®µå†å²ç‰¹å¾
        df['hour_minute'] = df['hour'] * 100 + df['minute']
        for days in [7, 14, 30]:
            periods = days * 96
            df[f'power_same_time_mean_{days}d'] = (
                df.groupby('hour_minute')['power']
                .rolling(window=days, min_periods=1)
                .mean()
                .reset_index(level=0, drop=True)
            )
        
        # å·®åˆ†ç‰¹å¾
        df['power_diff_1'] = df['power'].diff(1)
        df['power_diff_4'] = df['power'].diff(4)
        df['power_diff_96'] = df['power'].diff(96)
        
        # è¶‹åŠ¿ç‰¹å¾
        df['power_trend_4'] = df['power'].rolling(4).apply(lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) == 4 else 0, raw=False)
        df['power_trend_12'] = df['power'].rolling(12).apply(lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) == 12 else 0, raw=False)
        
        return df
    
    def train_station_model(self, station_id: str, test_size: float = 0.2):
        """è®­ç»ƒå•ä¸ªç«™ç‚¹çš„æ¨¡å‹"""
        print(f"\nğŸ¯ è®­ç»ƒ {station_id} æ¨¡å‹...")
        
        # åŠ è½½æ•°æ®
        df = self.load_station_data(station_id)
        print(f"  æ•°æ®èŒƒå›´: {df['date_time'].min()} åˆ° {df['date_time'].max()}")
        print(f"  æ•°æ®ç‚¹æ•°: {len(df):,}")
        
        # åˆ†æå†å²æ¨¡å¼
        self.analyze_historical_patterns(df, station_id)
        
        # åˆ›å»ºç‰¹å¾
        df = self.create_enhanced_features(df)
        
        # åªä¿ç•™ç™½å¤©æ—¶æ®µè¿›è¡Œè®­ç»ƒ
        daytime_mask = (df['is_daytime'] == 1) | (df['power'] > 0)
        df_daytime = df[daytime_mask].copy()
        
        # é€‰æ‹©ç‰¹å¾
        feature_cols = [col for col in df_daytime.columns 
                       if col not in ['date_time', 'power', 'hour_minute'] 
                       and not col.startswith('Unnamed')]
        
        # ç§»é™¤åŒ…å«NaNçš„è¡Œ
        df_clean = df_daytime.dropna()
        
        X = df_clean[feature_cols]
        y = df_clean['power']
        
        # æ—¶é—´åºåˆ—åˆ†å‰²
        split_idx = int(len(df_clean) * (1 - test_size))
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # è®­ç»ƒXGBoostæ¨¡å‹
        params = {
            'objective': 'reg:squarederror',
            'max_depth': 10,
            'learning_rate': 0.05,
            'n_estimators': 1000,
            'subsample': 0.9,
            'colsample_bytree': 0.9,
            'min_child_weight': 3,
            'gamma': 0.1,
            'random_state': 42,
            'n_jobs': -1
        }
        
        model = xgb.XGBRegressor(**params)
        model.fit(X_train, y_train, verbose=False)
        
        # è¯„ä¼°
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)
        
        train_metrics = self.calculate_metrics(y_train, y_train_pred)
        test_metrics = self.calculate_metrics(y_test, y_test_pred)
        
        print(f"  è®­ç»ƒé›† - MAE: {train_metrics['mae']:.4f}, RÂ²: {train_metrics['r2']:.4f}")
        print(f"  æµ‹è¯•é›† - MAE: {test_metrics['mae']:.4f}, RÂ²: {test_metrics['r2']:.4f}")
        
        # ä¿å­˜æ¨¡å‹å’Œç»“æœ
        self.models[station_id] = {
            'model': model,
            'feature_names': feature_cols,
            'train_metrics': train_metrics,
            'test_metrics': test_metrics,
            'data_info': {
                'total_records': len(df),
                'training_records': len(df_clean),
                'avg_power': df['power'].mean(),
                'max_power': df['power'].max()
            }
        }
        
        return df
    
    def calculate_metrics(self, y_true, y_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        r2 = r2_score(y_true, y_pred)
        return {'mae': mae, 'rmse': rmse, 'r2': r2}
    
    def predict_station_future(self, station_id: str, df: pd.DataFrame, forecast_days: int = 7):
        """é¢„æµ‹å•ä¸ªç«™ç‚¹çš„æœªæ¥åŠŸç‡"""
        if station_id not in self.models:
            raise ValueError(f"ç«™ç‚¹ {station_id} çš„æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        print(f"ğŸ”® é¢„æµ‹ {station_id} æœªæ¥ {forecast_days} å¤©åŠŸç‡...")
        
        model_info = self.models[station_id]
        model = model_info['model']
        feature_names = model_info['feature_names']
        patterns = self.historical_patterns[station_id]
        
        last_date = df['date_time'].max()
        forecast_periods = forecast_days * 96
        
        # åˆ›å»ºæœªæ¥æ—¶é—´åºåˆ—
        future_dates = pd.date_range(
            start=last_date + timedelta(minutes=15),
            periods=forecast_periods,
            freq='15T'
        )
        
        # å‡†å¤‡é¢„æµ‹æ•°æ®æ¡†
        future_df = pd.DataFrame({'date_time': future_dates, 'power': 0.0})
        extended_df = pd.concat([df, future_df], ignore_index=True)
        
        # åˆ›å»ºåŸºç¡€ç‰¹å¾
        extended_df = self.create_enhanced_features(extended_df)
        
        predictions = []
        start_idx = len(df)
        
        for i in range(start_idx, len(extended_df)):
            current_time = extended_df.loc[i, 'date_time']
            hour = current_time.hour
            time_slot = hour * 4 + current_time.minute // 15
            day_of_week = current_time.dayofweek
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºç™½å¤©
            is_daytime = (hour >= 22) or (hour <= 10)
            
            if is_daytime:
                try:
                    # é‡æ–°è®¡ç®—ç‰¹å¾
                    current_df = extended_df[:i+1].copy()
                    current_df = self.create_enhanced_features(current_df)
                    
                    if len(current_df) > 0:
                        feature_row = current_df.iloc[-1][feature_names]
                        
                        if not feature_row.isna().any():
                            X_pred = feature_row.values.reshape(1, -1)
                            pred = model.predict(X_pred)[0]
                            pred = max(0, pred)
                            
                            # å†å²æ¨¡å¼æ ¡æ­£
                            pred = self.apply_historical_correction(pred, hour, time_slot, day_of_week, patterns)
                        else:
                            pred = self.get_historical_baseline(hour, time_slot, day_of_week, patterns)
                    else:
                        pred = self.get_historical_baseline(hour, time_slot, day_of_week, patterns)
                        
                except Exception as e:
                    pred = self.get_historical_baseline(hour, time_slot, day_of_week, patterns)
            else:
                pred = 0
            
            # æ›´æ–°åŠŸç‡å€¼
            extended_df.loc[i, 'power'] = pred
            predictions.append(pred)
        
        # åˆ›å»ºç»“æœæ•°æ®æ¡†
        forecast_df = pd.DataFrame({
            'date_time': future_dates,
            'predicted_power': predictions
        })
        
        # ç»Ÿè®¡ç»“æœ
        total_avg = np.mean(predictions)
        total_max = np.max(predictions)
        
        # è®¡ç®—æ¯æ—¥å·®å¼‚
        daily_means = []
        for day in range(forecast_days):
            day_start = day * 96
            day_end = (day + 1) * 96
            if day_end <= len(predictions):
                daily_mean = np.mean(predictions[day_start:day_end])
                daily_means.append(daily_mean)
        
        daily_variance = np.var(daily_means) if len(daily_means) > 1 else 0
        
        print(f"  å¹³å‡åŠŸç‡: {total_avg:.3f} MW")
        print(f"  æœ€å¤§åŠŸç‡: {total_max:.3f} MW")
        print(f"  æ¯æ—¥æ–¹å·®: {daily_variance:.6f}")
        
        return forecast_df
    
    def apply_historical_correction(self, pred: float, hour: int, time_slot: int, day_of_week: int, patterns: dict) -> float:
        """åŸºäºå†å²æ¨¡å¼æ ¡æ­£é¢„æµ‹å€¼"""
        if hour in patterns['hourly'].index:
            hist_mean = patterns['hourly'].loc[hour, 'mean']
            hist_std = patterns['hourly'].loc[hour, 'std']
            hist_max = patterns['hourly'].loc[hour, 'max']
            
            # æ ¡æ­£åä½çš„é¢„æµ‹å€¼
            if pred < hist_mean * 0.3 and hist_mean > 1.0:
                correction_factor = np.random.uniform(0.7, 1.2)
                pred = hist_mean * correction_factor
            
            # é™åˆ¶è¿‡é«˜çš„é¢„æµ‹å€¼
            elif pred > hist_max * 1.1:
                pred = hist_max * np.random.uniform(0.9, 1.0)
            
            # æ·»åŠ éšæœºæ€§
            if hist_std > 0:
                noise = np.random.normal(0, hist_std * 0.1)
                pred = max(0, pred + noise)
        
        return pred
    
    def get_historical_baseline(self, hour: int, time_slot: int, day_of_week: int, patterns: dict) -> float:
        """è·å–å†å²åŸºå‡†å€¼"""
        if hour in patterns['hourly'].index:
            hist_mean = patterns['hourly'].loc[hour, 'mean']
            hist_std = patterns['hourly'].loc[hour, 'std']
            
            if hist_std > 0:
                baseline = np.random.normal(hist_mean, hist_std * 0.3)
            else:
                baseline = hist_mean * np.random.uniform(0.8, 1.2)
            
            return max(0, baseline)
        
        return 0
    
    def run_multi_station_prediction(self, station_ids: list, forecast_days: int = 7):
        """è¿è¡Œå¤šç«™ç‚¹é¢„æµ‹"""
        print("ğŸŒ å¤šç«™ç‚¹å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹ç³»ç»Ÿ")
        print("="*60)
        
        results = {}
        
        for station_id in station_ids:
            start_time = time.time()
            
            # è®­ç»ƒæ¨¡å‹
            df = self.train_station_model(station_id)
            
            # é¢„æµ‹æœªæ¥
            forecast_df = self.predict_station_future(station_id, df, forecast_days)
            
            # ä¿å­˜ç»“æœ
            output_dir = Path("results")
            output_dir.mkdir(exist_ok=True)
            
            forecast_df.to_csv(output_dir / f"{station_id}_7day_forecast.csv", index=False)
            
            # ä¿å­˜æ¨¡å‹
            model_data = {
                'model': self.models[station_id]['model'],
                'feature_names': self.models[station_id]['feature_names'],
                'historical_patterns': self.historical_patterns[station_id]
            }
            joblib.dump(model_data, output_dir / f"{station_id}_xgboost_model.pkl")
            
            elapsed_time = time.time() - start_time
            print(f"  âœ… {station_id} å®Œæˆï¼Œè€—æ—¶ {elapsed_time:.1f}s")
            
            results[station_id] = {
                'forecast_df': forecast_df,
                'model_info': self.models[station_id],
                'elapsed_time': elapsed_time
            }
        
        self.results = results
        return results
    
    def generate_comparison_report(self):
        """ç”Ÿæˆå¤šç«™ç‚¹å¯¹æ¯”æŠ¥å‘Š"""
        print(f"\nğŸ“Š å¤šç«™ç‚¹é¢„æµ‹ç»“æœå¯¹æ¯”æŠ¥å‘Š")
        print("="*60)
        
        print(f"{'ç«™ç‚¹':<10} | {'å¹³å‡åŠŸç‡':<8} | {'æœ€å¤§åŠŸç‡':<8} | {'RÂ²å¾—åˆ†':<8} | {'MAE':<8}")
        print("-" * 60)
        
        for station_id, result in self.results.items():
            model_info = result['model_info']
            forecast_df = result['forecast_df']
            
            avg_power = forecast_df['predicted_power'].mean()
            max_power = forecast_df['predicted_power'].max()
            r2_score = model_info['test_metrics']['r2']
            mae = model_info['test_metrics']['mae']
            
            print(f"{station_id:<10} | {avg_power:8.3f} | {max_power:8.3f} | {r2_score:8.4f} | {mae:8.4f}")
        
        return self.results


def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    predictor = MultiStationPowerPredictor()
    
    # é€‰æ‹©è¦é¢„æµ‹çš„ç«™ç‚¹
    station_ids = ['station01', 'station04', 'station09']
    
    # è¿è¡Œå¤šç«™ç‚¹é¢„æµ‹
    results = predictor.run_multi_station_prediction(station_ids)
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    predictor.generate_comparison_report()
    
    print(f"\nğŸ‰ å¤šç«™ç‚¹é¢„æµ‹å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶ä¿å­˜åœ¨ results/ ç›®å½•ä¸‹")
    
    return predictor, results


if __name__ == "__main__":
    predictor, results = main() 