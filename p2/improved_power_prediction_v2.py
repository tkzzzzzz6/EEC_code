# æ”¹è¿›ç‰ˆå…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹æ¨¡å‹ - ä½¿ç”¨çœŸå®å†å²æ•°æ® + å¯è§†åŒ–
import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
import joblib
from pathlib import Path
import warnings
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.dates import DateFormatter
import matplotlib.dates as mdates

warnings.filterwarnings('ignore')

# æ›´å…¼å®¹çš„ä¸­æ–‡å­—ä½“è®¾ç½®
import matplotlib as mpl
try:
    # å°è¯•å¤šç§ä¸­æ–‡å­—ä½“
    font_candidates = [
        'C:/Windows/Fonts/simhei.ttf',
        'C:/Windows/Fonts/simsun.ttc', 
        'C:/Windows/Fonts/msyh.ttc',
        'SimHei', 'Microsoft YaHei', 'SimSun'
    ]
    
    font_set = False
    for font in font_candidates:
        try:
            if font.endswith('.ttf') or font.endswith('.ttc'):
                mpl.font_manager.fontManager.addfont(font)
                font_name = mpl.font_manager.FontProperties(fname=font).get_name()
                plt.rcParams['font.sans-serif'] = [font_name]
            else:
                plt.rcParams['font.sans-serif'] = [font]
            font_set = True
            break
        except:
            continue
    
    if not font_set:
        # å¦‚æœéƒ½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        
except Exception as e:
    # å¤‡ç”¨æ–¹æ¡ˆ
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans']

plt.rcParams['axes.unicode_minus'] = False
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

# è®¾ç½®ä¸æ˜¾ç¤ºå›¾ç‰‡å¼¹çª—
plt.ioff()

class ImprovedPowerPredictionV2:
    """æ”¹è¿›ç‰ˆå…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹æ¨¡å‹ - ä½¿ç”¨çœŸå®å†å²æ•°æ®"""
    
    def __init__(self, station_id: str):
        self.station_id = station_id
        self.model = None
        self.feature_names = []
        self.historical_patterns = {}
        self.capacity = None
        self.train_data = None
        self.test_data = None
        self.predictions = None
        
    def load_and_preprocess_data(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®"""
        print(f"ğŸ“Š åŠ è½½ {self.station_id} æ•°æ®...")
        
        # åŠ è½½æ•°æ®
        df = pd.read_csv(f'data/{self.station_id}.csv')
        df['date_time'] = pd.to_datetime(df['date_time'])
        df = df.sort_values('date_time').reset_index(drop=True)
        
        # ä¼°ç®—å¼€æœºå®¹é‡ï¼ˆå†å²æœ€å¤§åŠŸç‡çš„1.1å€ï¼‰
        self.capacity = df['power'].max() * 1.1
        
        print(f"  æ•°æ®æ—¶é—´èŒƒå›´: {df['date_time'].min()} åˆ° {df['date_time'].max()}")
        print(f"  æ•°æ®ç‚¹æ•°: {len(df):,}")
        print(f"  å¹³å‡åŠŸç‡: {df['power'].mean():.3f} MW")
        print(f"  æœ€å¤§åŠŸç‡: {df['power'].max():.3f} MW")
        print(f"  ä¼°ç®—å¼€æœºå®¹é‡: {self.capacity:.3f} MW")
        
        return df
    
    def create_features(self, df):
        """åˆ›å»ºç‰¹å¾å·¥ç¨‹"""
        print("ğŸ”§ åˆ›å»ºç‰¹å¾å·¥ç¨‹...")
        
        # å¤åˆ¶æ•°æ®
        data = df.copy()
        
        # æ—¶é—´ç‰¹å¾
        data['hour'] = data['date_time'].dt.hour
        data['minute'] = data['date_time'].dt.minute
        data['day_of_week'] = data['date_time'].dt.dayofweek
        data['day_of_year'] = data['date_time'].dt.dayofyear
        data['month'] = data['date_time'].dt.month
        data['time_slot'] = data['hour'] * 4 + data['minute'] // 15
        
        # å‘¨æœŸæ€§ç‰¹å¾
        data['hour_sin'] = np.sin(2 * np.pi * data['hour'] / 24)
        data['hour_cos'] = np.cos(2 * np.pi * data['hour'] / 24)
        data['time_slot_sin'] = np.sin(2 * np.pi * data['time_slot'] / 96)
        data['time_slot_cos'] = np.cos(2 * np.pi * data['time_slot'] / 96)
        
        # æ»åç‰¹å¾
        lag_periods = [1, 2, 3, 4, 8, 12, 24, 48, 96, 192, 288, 672]
        for lag in lag_periods:
            data[f'power_lag_{lag}'] = data['power'].shift(lag)
        
        # æ»šåŠ¨ç»Ÿè®¡ç‰¹å¾
        windows = [4, 8, 12, 24, 48, 96]
        for window in windows:
            data[f'power_rolling_mean_{window}'] = data['power'].rolling(window=window).mean()
            data[f'power_rolling_std_{window}'] = data['power'].rolling(window=window).std()
            data[f'power_rolling_max_{window}'] = data['power'].rolling(window=window).max()
            data[f'power_rolling_min_{window}'] = data['power'].rolling(window=window).min()
        
        # å·®åˆ†ç‰¹å¾
        data['power_diff_1'] = data['power'].diff(1)
        data['power_diff_4'] = data['power'].diff(4)
        data['power_diff_24'] = data['power'].diff(24)
        data['power_diff_96'] = data['power'].diff(96)
        
        # å†å²åŒæœŸç‰¹å¾
        data['power_same_hour_7d'] = data['power'].shift(7*96)
        data['power_same_hour_14d'] = data['power'].shift(14*96)
        data['power_same_hour_30d'] = data['power'].shift(30*96)
        
        # è¶‹åŠ¿ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆï¼Œé¿å…æ•°å€¼é—®é¢˜ï¼‰
        data['power_trend_short'] = data['power'].rolling(window=12).mean().diff()
        data['power_trend_long'] = data['power'].rolling(window=96).mean().diff()
        
        # ç™½å¤©åˆ¤æ–­ï¼ˆåŸºäºUTCæ—¶é—´ï¼Œ22:00-10:00ä¸ºç™½å¤©ï¼‰
        data['is_daytime'] = ((data['hour'] >= 22) | (data['hour'] <= 10)).astype(int)
        
        # åŠŸç‡å˜åŒ–ç‡ï¼ˆå¤„ç†é™¤é›¶é—®é¢˜ï¼‰
        data['power_change_rate'] = data['power'].pct_change().fillna(0)
        data['power_change_rate'] = data['power_change_rate'].replace([np.inf, -np.inf], 0)
        data['power_acceleration'] = data['power_change_rate'].diff().fillna(0)
        
        # å¡«å……ç¼ºå¤±å€¼å’Œå¤„ç†æ— ç©·å¤§å€¼
        data = data.fillna(0)
        data = data.replace([np.inf, -np.inf], 0)
        
        # æ£€æŸ¥å¹¶å¤„ç†å¼‚å¸¸å€¼
        for col in data.columns:
            if col not in ['date_time']:
                # å°†æå¤§å€¼é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
                if data[col].dtype in ['float64', 'int64']:
                    q99 = data[col].quantile(0.99)
                    q01 = data[col].quantile(0.01)
                    data[col] = data[col].clip(lower=q01, upper=q99)
        
        print(f"  ç‰¹å¾æ•°é‡: {len(data.columns) - 2}")  # å‡å»date_timeå’Œpower
        
        return data
    
    def split_data(self, data, test_days=7):
        """åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®"""
        print(f"ğŸ“Š åˆ†å‰²æ•°æ® - æœ€å{test_days}å¤©ä½œä¸ºæµ‹è¯•é›†...")
        
        # æŒ‰æ—¶é—´åˆ†å‰²ï¼Œæœ€åtest_dayså¤©ä½œä¸ºæµ‹è¯•é›†
        test_start_idx = len(data) - test_days * 96  # æ¯å¤©96ä¸ª15åˆ†é’Ÿé—´éš”
        
        train_data = data[:test_start_idx].copy()
        test_data = data[test_start_idx:].copy()
        
        print(f"  è®­ç»ƒé›†: {len(train_data):,} æ¡è®°å½•")
        print(f"  æµ‹è¯•é›†: {len(test_data):,} æ¡è®°å½•")
        print(f"  è®­ç»ƒé›†æ—¶é—´èŒƒå›´: {train_data['date_time'].min()} åˆ° {train_data['date_time'].max()}")
        print(f"  æµ‹è¯•é›†æ—¶é—´èŒƒå›´: {test_data['date_time'].min()} åˆ° {test_data['date_time'].max()}")
        
        return train_data, test_data
    
    def train_model(self, train_data):
        """è®­ç»ƒXGBoostæ¨¡å‹"""
        print("ğŸš€ è®­ç»ƒXGBoostæ¨¡å‹...")
        
        # åªä½¿ç”¨ç™½å¤©æ—¶æ®µçš„æ•°æ®è¿›è¡Œè®­ç»ƒ
        daytime_mask = train_data['is_daytime'] == 1
        train_subset = train_data[daytime_mask].copy()
        
        # ç§»é™¤ç¼ºå¤±å€¼è¿‡å¤šçš„è¡Œ
        train_subset = train_subset.dropna()
        
        if len(train_subset) == 0:
            raise ValueError("æ²¡æœ‰è¶³å¤Ÿçš„è®­ç»ƒæ•°æ®")
        
        # ç‰¹å¾å’Œç›®æ ‡å˜é‡
        feature_cols = [col for col in train_subset.columns 
                       if col not in ['date_time', 'power']]
        X_train = train_subset[feature_cols]
        y_train = train_subset['power']
        
        self.feature_names = feature_cols
        
        # è®­ç»ƒæ¨¡å‹
        self.model = xgb.XGBRegressor(
            objective='reg:squarederror',
            max_depth=10,
            learning_rate=0.05,
            n_estimators=500,
            subsample=0.9,
            colsample_bytree=0.9,
            min_child_weight=3,
            gamma=0.1,
            random_state=42,
            n_jobs=-1
        )
        
        self.model.fit(X_train, y_train)
        
        # è®­ç»ƒé›†æ€§èƒ½
        train_pred = self.model.predict(X_train)
        train_r2 = r2_score(y_train, train_pred)
        train_mae = mean_absolute_error(y_train, train_pred)
        
        print(f"  è®­ç»ƒé›† RÂ²: {train_r2:.4f}")
        print(f"  è®­ç»ƒé›† MAE: {train_mae:.4f}")
        
        return self.model
    
    def predict_test_period(self, test_data):
        """é¢„æµ‹æµ‹è¯•æœŸé—´çš„åŠŸç‡"""
        print("ğŸ”® é¢„æµ‹æµ‹è¯•æœŸé—´åŠŸç‡...")
        
        predictions = []
        
        for idx, row in test_data.iterrows():
            # å‡†å¤‡ç‰¹å¾
            features = row[self.feature_names].values.reshape(1, -1)
            
            # é¢„æµ‹
            pred = self.model.predict(features)[0]
            
            # ç¡®ä¿é¢„æµ‹å€¼éè´Ÿ
            pred = max(0, pred)
            
            # å¤œé—´æ—¶æ®µè®¾ä¸º0
            if row['is_daytime'] == 0:
                pred = 0
            
            predictions.append(pred)
        
        return np.array(predictions)
    
    def calculate_evaluation_metrics(self, actual, predicted):
        """è®¡ç®—è¯„ä»·æŒ‡æ ‡"""
        # åªè®¡ç®—ç™½å¤©æ—¶æ®µçš„æŒ‡æ ‡
        daytime_mask = (actual > 0) | (predicted > 0)
        
        if np.sum(daytime_mask) == 0:
            return {}
        
        actual_day = actual[daytime_mask]
        predicted_day = predicted[daytime_mask]
        
        # å½’ä¸€åŒ–è¯¯å·®ï¼ˆç›¸å¯¹äºå¼€æœºå®¹é‡ï¼‰
        normalized_actual = actual_day / self.capacity
        normalized_predicted = predicted_day / self.capacity
        normalized_error = normalized_predicted - normalized_actual
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        rmse = np.sqrt(np.mean(normalized_error ** 2))
        mae = np.mean(np.abs(normalized_error))
        me = np.mean(normalized_error)
        
        # ç›¸å…³ç³»æ•°
        if len(actual_day) > 1:
            correlation = np.corrcoef(actual_day, predicted_day)[0, 1]
        else:
            correlation = 0
        
        # å‡†ç¡®ç‡
        accuracy = (1 - rmse) * 100
        
        # åˆæ ¼ç‡ï¼ˆè¯¯å·®å°äº25%çš„æ¯”ä¾‹ï¼‰
        qualification_mask = np.abs(normalized_error) < 0.25
        qualification_rate = np.mean(qualification_mask) * 100
        
        return {
            'RMSE': rmse,
            'MAE': mae,
            'ME': me,
            'Correlation': correlation,
            'Accuracy': accuracy,
            'Qualification_Rate': qualification_rate,
            'Sample_Count': len(actual_day)
        }
    
    def create_visualizations(self, test_data, predictions):
        """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
        print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        # åˆ›å»ºå›¾è¡¨ç›®å½•
        fig_dir = Path("results/figures")
        fig_dir.mkdir(exist_ok=True)
        
        # 1. é¢„æµ‹vså®é™…å¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'{self.station_id} å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹åˆ†æ', fontsize=16, fontweight='bold')
        
        # æ—¶é—´åºåˆ—å¯¹æ¯”
        ax1 = axes[0, 0]
        time_range = test_data['date_time']
        ax1.plot(time_range, test_data['power'], label='å®é™…åŠŸç‡', linewidth=2, alpha=0.8)
        ax1.plot(time_range, predictions, label='é¢„æµ‹åŠŸç‡', linewidth=2, alpha=0.8)
        ax1.set_title('é¢„æµ‹vså®é™…åŠŸç‡æ—¶é—´åºåˆ—å¯¹æ¯”')
        ax1.set_xlabel('æ—¶é—´')
        ax1.set_ylabel('åŠŸç‡ (MW)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ ¼å¼åŒ–xè½´æ—¥æœŸ
        ax1.xaxis.set_major_formatter(DateFormatter('%m-%d'))
        ax1.xaxis.set_major_locator(mdates.DayLocator(interval=1))
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # æ•£ç‚¹å›¾
        ax2 = axes[0, 1]
        ax2.scatter(test_data['power'], predictions, alpha=0.6, s=20)
        max_power = max(test_data['power'].max(), predictions.max())
        ax2.plot([0, max_power], [0, max_power], 'r--', label='ç†æƒ³é¢„æµ‹çº¿')
        ax2.set_title('é¢„æµ‹vså®é™…åŠŸç‡æ•£ç‚¹å›¾')
        ax2.set_xlabel('å®é™…åŠŸç‡ (MW)')
        ax2.set_ylabel('é¢„æµ‹åŠŸç‡ (MW)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # è¯¯å·®åˆ†å¸ƒ
        ax3 = axes[1, 0]
        errors = predictions - test_data['power']
        ax3.hist(errors, bins=30, alpha=0.7, edgecolor='black')
        ax3.axvline(errors.mean(), color='red', linestyle='--', 
                   label=f'å¹³å‡è¯¯å·®: {errors.mean():.3f}')
        ax3.set_title('é¢„æµ‹è¯¯å·®åˆ†å¸ƒ')
        ax3.set_xlabel('é¢„æµ‹è¯¯å·® (MW)')
        ax3.set_ylabel('é¢‘æ¬¡')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # æ—¥å†…åŠŸç‡æ¨¡å¼
        ax4 = axes[1, 1]
        test_data_copy = test_data.copy()
        test_data_copy['hour'] = test_data_copy['date_time'].dt.hour
        test_data_copy['predictions'] = predictions
        
        hourly_actual = test_data_copy.groupby('hour')['power'].mean()
        hourly_predicted = test_data_copy.groupby('hour')['predictions'].mean()
        
        ax4.plot(hourly_actual.index, hourly_actual.values, 'o-', label='å®é™…å¹³å‡åŠŸç‡', linewidth=2)
        ax4.plot(hourly_predicted.index, hourly_predicted.values, 's-', label='é¢„æµ‹å¹³å‡åŠŸç‡', linewidth=2)
        ax4.set_title('æ—¥å†…å¹³å‡åŠŸç‡æ¨¡å¼å¯¹æ¯”')
        ax4.set_xlabel('å°æ—¶')
        ax4.set_ylabel('å¹³å‡åŠŸç‡ (MW)')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        ax4.set_xticks(range(0, 24, 2))
        
        plt.tight_layout()
        plt.savefig(fig_dir / f'{self.station_id}_prediction_analysis.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾ç‰‡ï¼Œä¸æ˜¾ç¤ºå¼¹çª—
        
        # 2. ç‰¹å¾é‡è¦æ€§å›¾
        if hasattr(self.model, 'feature_importances_'):
            self.plot_feature_importance(fig_dir)
        
        # 3. è¯„ä»·æŒ‡æ ‡é›·è¾¾å›¾
        metrics = self.calculate_evaluation_metrics(test_data['power'].values, predictions)
        if metrics:
            self.plot_metrics_radar(metrics, fig_dir)
        
        # 4. æ¯æ—¥é¢„æµ‹æ€§èƒ½å¯¹æ¯”
        self.plot_daily_performance(test_data, predictions, fig_dir)
    
    def plot_feature_importance(self, fig_dir):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        importances = self.model.feature_importances_
        feature_importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'importance': importances
        }).sort_values('importance', ascending=False)
        
        # å–å‰20ä¸ªé‡è¦ç‰¹å¾
        top_features = feature_importance_df.head(20)
        
        plt.figure(figsize=(12, 8))
        sns.barplot(data=top_features, y='feature', x='importance')
        plt.title(f'{self.station_id} ç‰¹å¾é‡è¦æ€§æ’åº (Top 20)')
        plt.xlabel('é‡è¦æ€§å¾—åˆ†')
        plt.ylabel('ç‰¹å¾åç§°')
        plt.tight_layout()
        plt.savefig(fig_dir / f'{self.station_id}_feature_importance.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾ç‰‡ï¼Œä¸æ˜¾ç¤ºå¼¹çª—
    
    def plot_metrics_radar(self, metrics, fig_dir):
        """ç»˜åˆ¶è¯„ä»·æŒ‡æ ‡é›·è¾¾å›¾"""
        # å‡†å¤‡é›·è¾¾å›¾æ•°æ®
        categories = ['å‡†ç¡®ç‡', 'åˆæ ¼ç‡', 'ç›¸å…³ç³»æ•°', 'RMSE(å)', 'MAE(å)', 'ME(å)']
        values = [
            metrics['Accuracy'],
            metrics['Qualification_Rate'],
            metrics['Correlation'] * 100,  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            (1 - metrics['RMSE']) * 100,   # åå‘ï¼Œè¶Šå¤§è¶Šå¥½
            (1 - metrics['MAE']) * 100,    # åå‘ï¼Œè¶Šå¤§è¶Šå¥½
            (1 - abs(metrics['ME'])) * 100  # åå‘ï¼Œè¶Šå¤§è¶Šå¥½
        ]
        
        # åˆ›å»ºé›·è¾¾å›¾
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False)
        values += values[:1]  # é—­åˆå›¾å½¢
        angles = np.concatenate((angles, [angles[0]]))
        
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
        ax.plot(angles, values, 'o-', linewidth=2, label=self.station_id)
        ax.fill(angles, values, alpha=0.25)
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories)
        ax.set_ylim(0, 100)
        ax.set_title(f'{self.station_id} é¢„æµ‹æ€§èƒ½é›·è¾¾å›¾', size=16, fontweight='bold', pad=20)
        ax.grid(True)
        
        plt.tight_layout()
        plt.savefig(fig_dir / f'{self.station_id}_metrics_radar.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾ç‰‡ï¼Œä¸æ˜¾ç¤ºå¼¹çª—
    
    def plot_daily_performance(self, test_data, predictions, fig_dir):
        """ç»˜åˆ¶æ¯æ—¥é¢„æµ‹æ€§èƒ½å¯¹æ¯”"""
        test_data_copy = test_data.copy()
        test_data_copy['predictions'] = predictions
        test_data_copy['date'] = test_data_copy['date_time'].dt.date
        
        # è®¡ç®—æ¯æ—¥ç»Ÿè®¡
        daily_stats = test_data_copy.groupby('date').agg({
            'power': ['mean', 'max', 'sum'],
            'predictions': ['mean', 'max', 'sum']
        }).round(3)
        
        daily_stats.columns = ['å®é™…å¹³å‡', 'å®é™…æœ€å¤§', 'å®é™…æ€»å’Œ', 'é¢„æµ‹å¹³å‡', 'é¢„æµ‹æœ€å¤§', 'é¢„æµ‹æ€»å’Œ']
        
        # ç»˜åˆ¶æ¯æ—¥å¯¹æ¯”å›¾
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        fig.suptitle(f'{self.station_id} æ¯æ—¥é¢„æµ‹æ€§èƒ½å¯¹æ¯”', fontsize=16, fontweight='bold')
        
        # æ¯æ—¥å¹³å‡åŠŸç‡
        ax1 = axes[0, 0]
        ax1.plot(daily_stats.index, daily_stats['å®é™…å¹³å‡'], 'o-', label='å®é™…å¹³å‡', linewidth=2)
        ax1.plot(daily_stats.index, daily_stats['é¢„æµ‹å¹³å‡'], 's-', label='é¢„æµ‹å¹³å‡', linewidth=2)
        ax1.set_title('æ¯æ—¥å¹³å‡åŠŸç‡å¯¹æ¯”')
        ax1.set_ylabel('å¹³å‡åŠŸç‡ (MW)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)
        
        # æ¯æ—¥æœ€å¤§åŠŸç‡
        ax2 = axes[0, 1]
        ax2.plot(daily_stats.index, daily_stats['å®é™…æœ€å¤§'], 'o-', label='å®é™…æœ€å¤§', linewidth=2)
        ax2.plot(daily_stats.index, daily_stats['é¢„æµ‹æœ€å¤§'], 's-', label='é¢„æµ‹æœ€å¤§', linewidth=2)
        ax2.set_title('æ¯æ—¥æœ€å¤§åŠŸç‡å¯¹æ¯”')
        ax2.set_ylabel('æœ€å¤§åŠŸç‡ (MW)')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
        
        # æ¯æ—¥å‘ç”µé‡
        ax3 = axes[1, 0]
        ax3.plot(daily_stats.index, daily_stats['å®é™…æ€»å’Œ'], 'o-', label='å®é™…å‘ç”µé‡', linewidth=2)
        ax3.plot(daily_stats.index, daily_stats['é¢„æµ‹æ€»å’Œ'], 's-', label='é¢„æµ‹å‘ç”µé‡', linewidth=2)
        ax3.set_title('æ¯æ—¥å‘ç”µé‡å¯¹æ¯”')
        ax3.set_ylabel('å‘ç”µé‡ (MWh)')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)
        
        # æ¯æ—¥è¯¯å·®
        ax4 = axes[1, 1]
        daily_error = daily_stats['é¢„æµ‹å¹³å‡'] - daily_stats['å®é™…å¹³å‡']
        ax4.bar(range(len(daily_error)), daily_error, alpha=0.7)
        ax4.axhline(y=0, color='red', linestyle='--')
        ax4.set_title('æ¯æ—¥å¹³å‡åŠŸç‡é¢„æµ‹è¯¯å·®')
        ax4.set_ylabel('é¢„æµ‹è¯¯å·® (MW)')
        ax4.set_xticks(range(len(daily_error)))
        ax4.set_xticklabels([str(d) for d in daily_stats.index], rotation=45)
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(fig_dir / f'{self.station_id}_daily_performance.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()  # å…³é—­å›¾ç‰‡ï¼Œä¸æ˜¾ç¤ºå¼¹çª—
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        print(f"ğŸ¯ å¼€å§‹ {self.station_id} å®Œæ•´åˆ†æ...")
        
        # 1. åŠ è½½æ•°æ®
        df = self.load_and_preprocess_data()
        
        # 2. ç‰¹å¾å·¥ç¨‹
        data = self.create_features(df)
        
        # 3. åˆ†å‰²æ•°æ®
        self.train_data, self.test_data = self.split_data(data, test_days=7)
        
        # 4. è®­ç»ƒæ¨¡å‹
        self.train_model(self.train_data)
        
        # 5. é¢„æµ‹
        self.predictions = self.predict_test_period(self.test_data)
        
        # 6. è¯„ä¼°
        metrics = self.calculate_evaluation_metrics(
            self.test_data['power'].values, 
            self.predictions
        )
        
        # 7. å¯è§†åŒ–
        self.create_visualizations(self.test_data, self.predictions)
        
        # 8. ä¿å­˜ç»“æœ
        self.save_results(metrics)
        
        return metrics
    
    def save_results(self, metrics):
        """ä¿å­˜ç»“æœ"""
        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)
        
        # ä¿å­˜é¢„æµ‹ç»“æœ
        results_df = pd.DataFrame({
            'date_time': self.test_data['date_time'],
            'actual_power': self.test_data['power'],
            'predicted_power': self.predictions,
            'error': self.predictions - self.test_data['power']
        })
        
        results_df.to_csv(results_dir / f'{self.station_id}_prediction_results.csv', index=False)
        
        # ä¿å­˜æ¨¡å‹
        joblib.dump(self.model, results_dir / f'{self.station_id}_xgboost_model.pkl')
        
        # ä¿å­˜è¯„ä»·æŒ‡æ ‡
        metrics_df = pd.DataFrame([metrics])
        metrics_df.to_csv(results_dir / f'{self.station_id}_metrics.csv', index=False)
        
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° results/ ç›®å½•")

def run_multi_station_analysis():
    """è¿è¡Œå¤šç«™ç‚¹åˆ†æ"""
    stations = ['station00', 'station04', 'station05', 'station09']
    all_metrics = {}
    
    print("ğŸš€ å¼€å§‹å¤šç«™ç‚¹å…‰ä¼å‘ç”µåŠŸç‡é¢„æµ‹åˆ†æ...")
    print("="*60)
    
    for station in stations:
        try:
            print(f"\n{'='*20} {station} {'='*20}")
            predictor = ImprovedPowerPredictionV2(station)
            metrics = predictor.run_complete_analysis()
            all_metrics[station] = metrics
            
            print(f"\nğŸ“Š {station} è¯„ä»·æŒ‡æ ‡:")
            print(f"  RMSE: {metrics['RMSE']:.6f}")
            print(f"  MAE: {metrics['MAE']:.6f}")
            print(f"  ç›¸å…³ç³»æ•°: {metrics['Correlation']:.4f}")
            print(f"  å‡†ç¡®ç‡: {metrics['Accuracy']:.2f}%")
            print(f"  åˆæ ¼ç‡: {metrics['Qualification_Rate']:.2f}%")
            
        except Exception as e:
            print(f"âŒ {station} åˆ†æå¤±è´¥: {str(e)}")
            continue
    
    # ç”Ÿæˆç»¼åˆå¯¹æ¯”æŠ¥å‘Š
    if all_metrics:
        create_summary_comparison(all_metrics)
    
    print(f"\nğŸ‰ å¤šç«™ç‚¹åˆ†æå®Œæˆï¼")
    return all_metrics

def create_summary_comparison(all_metrics):
    """åˆ›å»ºç»¼åˆå¯¹æ¯”æŠ¥å‘Š"""
    print(f"\n{'='*60}")
    print("ğŸ“Š å¤šç«™ç‚¹é¢„æµ‹æ€§èƒ½ç»¼åˆå¯¹æ¯”")
    print("="*60)
    
    # åˆ›å»ºå¯¹æ¯”è¡¨æ ¼
    comparison_data = []
    for station, metrics in all_metrics.items():
        comparison_data.append({
            'ç«™ç‚¹': station,
            'RMSE': f"{metrics['RMSE']:.6f}",
            'MAE': f"{metrics['MAE']:.6f}",
            'ç›¸å…³ç³»æ•°': f"{metrics['Correlation']:.4f}",
            'å‡†ç¡®ç‡(%)': f"{metrics['Accuracy']:.2f}",
            'åˆæ ¼ç‡(%)': f"{metrics['Qualification_Rate']:.2f}",
            'æ ·æœ¬æ•°': metrics['Sample_Count']
        })
    
    comparison_df = pd.DataFrame(comparison_data)
    print(comparison_df.to_string(index=False))
    
    # ä¿å­˜å¯¹æ¯”ç»“æœ
    comparison_df.to_csv('results/multi_station_comparison.csv', index=False)
    
    # åˆ›å»ºç»¼åˆå¯¹æ¯”å¯è§†åŒ–
    create_comparison_visualization(all_metrics)

def create_comparison_visualization(all_metrics):
    """åˆ›å»ºç»¼åˆå¯¹æ¯”å¯è§†åŒ–"""
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('å¤šç«™ç‚¹é¢„æµ‹æ€§èƒ½ç»¼åˆå¯¹æ¯”', fontsize=16, fontweight='bold')
    
    stations = list(all_metrics.keys())
    
    # RMSEå¯¹æ¯”
    ax1 = axes[0, 0]
    rmse_values = [all_metrics[s]['RMSE'] for s in stations]
    bars1 = ax1.bar(stations, rmse_values, alpha=0.7)
    ax1.set_title('RMSEå¯¹æ¯” (è¶Šå°è¶Šå¥½)')
    ax1.set_ylabel('RMSE')
    ax1.grid(True, alpha=0.3)
    
    # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼
    for bar, value in zip(bars1, rmse_values):
        ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                f'{value:.3f}', ha='center', va='bottom')
    
    # å‡†ç¡®ç‡å¯¹æ¯”
    ax2 = axes[0, 1]
    accuracy_values = [all_metrics[s]['Accuracy'] for s in stations]
    bars2 = ax2.bar(stations, accuracy_values, alpha=0.7, color='green')
    ax2.set_title('å‡†ç¡®ç‡å¯¹æ¯” (è¶Šå¤§è¶Šå¥½)')
    ax2.set_ylabel('å‡†ç¡®ç‡ (%)')
    ax2.grid(True, alpha=0.3)
    
    for bar, value in zip(bars2, accuracy_values):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{value:.1f}%', ha='center', va='bottom')
    
    # åˆæ ¼ç‡å¯¹æ¯”
    ax3 = axes[1, 0]
    qr_values = [all_metrics[s]['Qualification_Rate'] for s in stations]
    bars3 = ax3.bar(stations, qr_values, alpha=0.7, color='orange')
    ax3.set_title('åˆæ ¼ç‡å¯¹æ¯” (è¶Šå¤§è¶Šå¥½)')
    ax3.set_ylabel('åˆæ ¼ç‡ (%)')
    ax3.grid(True, alpha=0.3)
    
    for bar, value in zip(bars3, qr_values):
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                f'{value:.1f}%', ha='center', va='bottom')
    
    # ç›¸å…³ç³»æ•°å¯¹æ¯”
    ax4 = axes[1, 1]
    corr_values = [all_metrics[s]['Correlation'] for s in stations]
    bars4 = ax4.bar(stations, corr_values, alpha=0.7, color='purple')
    ax4.set_title('ç›¸å…³ç³»æ•°å¯¹æ¯” (è¶Šå¤§è¶Šå¥½)')
    ax4.set_ylabel('ç›¸å…³ç³»æ•°')
    ax4.grid(True, alpha=0.3)
    
    for bar, value in zip(bars4, corr_values):
        ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{value:.3f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig('results/figures/multi_station_comparison.png', 
               dpi=300, bbox_inches='tight')
    plt.close()  # å…³é—­å›¾ç‰‡ï¼Œä¸æ˜¾ç¤ºå¼¹çª—

if __name__ == "__main__":
    # è¿è¡Œå¤šç«™ç‚¹åˆ†æ
    metrics = run_multi_station_analysis() 